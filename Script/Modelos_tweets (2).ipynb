{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importar librerías a utilizar"
      ],
      "metadata": {
        "id": "XREz8NEeM3yU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kTFOKBjC4lh",
        "outputId": "db1a7871-7584-4e5b-8f34-ab71d53a7742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.2.2\n",
            "Uninstalling scikit-learn-1.2.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.9/dist-packages/scikit_learn-1.2.2.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/scikit_learn.libs/libgomp-a34b3233.so.1.0.0\n",
            "    /usr/local/lib/python3.9/dist-packages/sklearn/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled scikit-learn-1.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.13\n",
            "  Downloading scikit-learn-0.13.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scikit-learn\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "Failed to build scikit-learn\n",
            "Installing collected packages: scikit-learn\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for scikit-learn\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for scikit-learn ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m scikit-learn\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall scikit-learn\n",
        "!pip install scikit-learn\n",
        "!pip install contexto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YxDnopEJTAr"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.decomposition import SparsePCA\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "from matplotlib import style\n",
        "style.use('ggplot') or plt.style.use('ggplot')\n",
        "\n",
        "import requests \n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from multiprocessing.dummy import Pool\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from contexto.limpieza import *\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "import time\n",
        "from contexto.stemming import Stemmer, stem_texto\n",
        "\n",
        "import time\n",
        "from contexto.lematizacion import LematizadorSpacy, LematizadorStanza\n",
        "from contexto.lematizacion import lematizar_texto\n",
        "\n",
        "from contexto.exploracion import obtener_ngramas\n",
        "from contexto.exploracion import nube_palabras\n",
        "from contexto.exploracion import par_nubes\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar bases de datos de entrenamiento y testeo"
      ],
      "metadata": {
        "id": "6lsWTRLlNFH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l6IRZR8E8aZ"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(r\"/content/train.csv\")\n",
        "test = pd.read_csv(r\"/content/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU5Vv9wFAgnB",
        "outputId": "2122a630-14c3-4e4b-e2f3-514da58a2cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         id   name  \\\n",
              "0  5f993ca6ab24ecb07efc5259  Petro   \n",
              "1  f8734ee208059bc34690fbe8  Lopez   \n",
              "2  cfd3678247b29ea7ba1fbe3c  Lopez   \n",
              "3  e13d9e299ac5ffd38f503c5a  Lopez   \n",
              "4  fc457807261de42e57f5c1c5  Petro   \n",
              "\n",
              "                                                text  \n",
              "0  Me gustaría que esta columna fuera deliberada ...  \n",
              "1  ¡Si Bogotá y Cundinamarca salen adelante Colom...  \n",
              "2  Esto significa el proyecto de acuerdo de resca...  \n",
              "3  ¡Avanza nuestro recorrido por San Cristóbal! \\...  \n",
              "4  Miles de personas en Bucaramanga en estos mome...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23c9fcff-662e-4a4a-999e-3e5fdd23e034\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f993ca6ab24ecb07efc5259</td>\n",
              "      <td>Petro</td>\n",
              "      <td>Me gustaría que esta columna fuera deliberada ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f8734ee208059bc34690fbe8</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>¡Si Bogotá y Cundinamarca salen adelante Colom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cfd3678247b29ea7ba1fbe3c</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>Esto significa el proyecto de acuerdo de resca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e13d9e299ac5ffd38f503c5a</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>¡Avanza nuestro recorrido por San Cristóbal! \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fc457807261de42e57f5c1c5</td>\n",
              "      <td>Petro</td>\n",
              "      <td>Miles de personas en Bucaramanga en estos mome...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23c9fcff-662e-4a4a-999e-3e5fdd23e034')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23c9fcff-662e-4a4a-999e-3e5fdd23e034 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23c9fcff-662e-4a4a-999e-3e5fdd23e034');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train.head() # Ver los primeros 5 tweets de la base de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpiar tweets de las bases de entrenamiento y testeo"
      ],
      "metadata": {
        "id": "qIPSdxcgNJbt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfvlQgQJIoEe"
      },
      "outputs": [],
      "source": [
        "# Convertir en lista cada una de las columnas de la base de entrenamiento y testeo\n",
        "text_train ={'id': train['id'].to_list(),'name': train['name'].to_list(), 'text': train['text'].to_list()}\n",
        "text_test ={'id': test['id'].to_list(), 'text': test['text'].to_list()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf7EU0L2IoCP"
      },
      "outputs": [],
      "source": [
        "# Definir la lista de stopwords\n",
        "stopwords = []\n",
        "lis = [lista_nombres()[0], lista_apellidos()[0],lista_geo_colombia()[0], lista_geo_colombia()[1], \n",
        "       lista_stopwords()]\n",
        "for i in lis:\n",
        "    stopwords.extend(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVASohr6IoAI"
      },
      "outputs": [],
      "source": [
        "# Crear función para limpiar el texto\n",
        "def limpiar(text):\n",
        "    text = remover_stopwords(text, lista_palabras= stopwords)\n",
        "    text = re.sub(r\"http\\S+\", \"\", text) # Eliminar hipervínculos\n",
        "    text = quitar_repetidos(text, \",\") # Eliminar palabras que, estando una coma, están repetidas\n",
        "    text = limpieza_basica(text) # Eliminar signos de puntuación, números y transformar todo a minúscula\n",
        "    text = remover_acentos(text) # Eliminar acentos\n",
        "    text = remover_palabras_cortas(text, 4) # Eliminar palabras que tengan 4 caracteres o menos\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "YL74v6xBIn9l",
        "outputId": "20fd6ea2-f79f-411c-e5ef-64efefad69e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9349/9349 [04:51<00:00, 32.09it/s]\n",
            "100%|██████████| 9349/9349 [00:05<00:00, 1763.85it/s]\n",
            "100%|██████████| 9349/9349 [00:42<00:00, 217.78it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id   name  \\\n",
              "0     5f993ca6ab24ecb07efc5259  Petro   \n",
              "1     f8734ee208059bc34690fbe8  Lopez   \n",
              "2     cfd3678247b29ea7ba1fbe3c  Lopez   \n",
              "3     e13d9e299ac5ffd38f503c5a  Lopez   \n",
              "4     fc457807261de42e57f5c1c5  Petro   \n",
              "...                        ...    ...   \n",
              "9344  a9bbd1f1a75509dfbfd58989  Uribe   \n",
              "9345  5444d8088d86cbb383ea478c  Petro   \n",
              "9346  ea1e50eeb549aa47ea59a9db  Uribe   \n",
              "9347  7746b5b0907344492c91201e  Lopez   \n",
              "9348  bcc480ee8f9e59966c25c865  Petro   \n",
              "\n",
              "                                                   text  \n",
              "0     gustario columna deliberado punto resistencia ...  \n",
              "1     salir adelante adelante trabajar junto reconoc...  \n",
              "2     este significar proyecto acuerdo rescate socia...  \n",
              "3     avanzar recorrido cristobal llegar colegio ter...  \n",
              "4     mil persona momento calle paronacional termina...  \n",
              "...                                                 ...  \n",
              "9344  apoyar construccion politico jovenes austerida...  \n",
              "9345  educacion superior duda clave disminucion desi...  \n",
              "9346  jovenes anos desempleado trofimoff foro centro...  \n",
              "9347  material ir recuperar vida perder cambio doler...  \n",
              "9348  agradecer hospitalidad fraternidad alcaldés ir...  \n",
              "\n",
              "[9349 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d8ac156-0988-4d0b-8d5d-3b1d40b03e1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f993ca6ab24ecb07efc5259</td>\n",
              "      <td>Petro</td>\n",
              "      <td>gustario columna deliberado punto resistencia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f8734ee208059bc34690fbe8</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>salir adelante adelante trabajar junto reconoc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cfd3678247b29ea7ba1fbe3c</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>este significar proyecto acuerdo rescate socia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e13d9e299ac5ffd38f503c5a</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>avanzar recorrido cristobal llegar colegio ter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fc457807261de42e57f5c1c5</td>\n",
              "      <td>Petro</td>\n",
              "      <td>mil persona momento calle paronacional termina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9344</th>\n",
              "      <td>a9bbd1f1a75509dfbfd58989</td>\n",
              "      <td>Uribe</td>\n",
              "      <td>apoyar construccion politico jovenes austerida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9345</th>\n",
              "      <td>5444d8088d86cbb383ea478c</td>\n",
              "      <td>Petro</td>\n",
              "      <td>educacion superior duda clave disminucion desi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9346</th>\n",
              "      <td>ea1e50eeb549aa47ea59a9db</td>\n",
              "      <td>Uribe</td>\n",
              "      <td>jovenes anos desempleado trofimoff foro centro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9347</th>\n",
              "      <td>7746b5b0907344492c91201e</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>material ir recuperar vida perder cambio doler...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9348</th>\n",
              "      <td>bcc480ee8f9e59966c25c865</td>\n",
              "      <td>Petro</td>\n",
              "      <td>agradecer hospitalidad fraternidad alcaldés ir...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9349 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d8ac156-0988-4d0b-8d5d-3b1d40b03e1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d8ac156-0988-4d0b-8d5d-3b1d40b03e1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d8ac156-0988-4d0b-8d5d-3b1d40b03e1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Aplicar la función de limpieza creada y aplicar stemmer y lematizador a la base de entrenamiento\n",
        "re_limp=[]\n",
        "\n",
        "for i in tqdm(text_train['text']):\n",
        "    re_limp.append(limpiar(i))\n",
        "\n",
        "# Stemmer\n",
        "stemmer = Stemmer(lenguaje='español')\n",
        "\n",
        "corpus_stem=[]\n",
        "for i in tqdm(re_limp):\n",
        "    stem = stem_texto(i, stemmer=stemmer)\n",
        "    corpus_stem.append(stem)\n",
        "\n",
        "train_stem = train.drop(['text'], axis=1)\n",
        "train_stem['text'] = corpus_stem\n",
        "\n",
        "# Lematizador\n",
        "lematizador = LematizadorSpacy('es')\n",
        "\n",
        "corpus_lem =[]\n",
        "for i in tqdm(re_limp):\n",
        "    lem = lematizar_texto(i, lematizador=lematizador)\n",
        "    corpus_lem.append(lem)\n",
        "\n",
        "train_lem = train.drop(['text'], axis=1)\n",
        "train_lem['text'] = corpus_lem\n",
        "\n",
        "train_lem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWBHRWzlKjjv"
      },
      "source": [
        "## Testeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "COlpHYB5nmbw",
        "outputId": "7a5c01cc-2e7c-4e59-937b-260722a3d32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:45<00:00, 33.01it/s]\n",
            "100%|██████████| 1500/1500 [00:00<00:00, 1847.50it/s]\n",
            "100%|██████████| 1500/1500 [00:08<00:00, 184.24it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id  \\\n",
              "0     6f4f09622255e9d9d76251b4   \n",
              "1     aefd318f57227e4053f64191   \n",
              "2     d1eb53be99fa263c10911af9   \n",
              "3     bb65250f1ff7582e4380a9c9   \n",
              "4     0017570ee84b80e1c3e10218   \n",
              "...                        ...   \n",
              "1495  4d1dc06d6ca8d0da93ceb42a   \n",
              "1496  db282aa075d8ffb4dc9d72ae   \n",
              "1497  afaac0a39ec1ea5f58308407   \n",
              "1498  262b591834494af862ed6f09   \n",
              "1499  617192c47672548910aca070   \n",
              "\n",
              "                                                   text  \n",
              "0     ruego procuradora general diferenciar alcaldio...  \n",
              "1     millón peso invertido ipial instalacion acomet...  \n",
              "2     luchar crisis climatico implicar cambiar movil...  \n",
              "3     opinionescruzada rcnradio rete publicamente qu...  \n",
              "4     ante amenaza sistematico reduccion fuerza poli...  \n",
              "...                                                 ...  \n",
              "1495  pedir perdon periodico debate senadoro paola h...  \n",
              "1496  estilo politico visión pai odio clase destrucc...  \n",
              "1497  urgente informar companera pueblo embera katio...  \n",
              "1498  empresa avicola poder sacar huevo entrar alime...  \n",
              "1499                                     ueveanlaverdad  \n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bb8bb14-e24c-4074-aae1-0bdf7f17c5ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f4f09622255e9d9d76251b4</td>\n",
              "      <td>ruego procuradora general diferenciar alcaldio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aefd318f57227e4053f64191</td>\n",
              "      <td>millón peso invertido ipial instalacion acomet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d1eb53be99fa263c10911af9</td>\n",
              "      <td>luchar crisis climatico implicar cambiar movil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bb65250f1ff7582e4380a9c9</td>\n",
              "      <td>opinionescruzada rcnradio rete publicamente qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0017570ee84b80e1c3e10218</td>\n",
              "      <td>ante amenaza sistematico reduccion fuerza poli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>4d1dc06d6ca8d0da93ceb42a</td>\n",
              "      <td>pedir perdon periodico debate senadoro paola h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>db282aa075d8ffb4dc9d72ae</td>\n",
              "      <td>estilo politico visión pai odio clase destrucc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>afaac0a39ec1ea5f58308407</td>\n",
              "      <td>urgente informar companera pueblo embera katio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>262b591834494af862ed6f09</td>\n",
              "      <td>empresa avicola poder sacar huevo entrar alime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>617192c47672548910aca070</td>\n",
              "      <td>ueveanlaverdad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bb8bb14-e24c-4074-aae1-0bdf7f17c5ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bb8bb14-e24c-4074-aae1-0bdf7f17c5ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bb8bb14-e24c-4074-aae1-0bdf7f17c5ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Aplicar la función de limpieza creada y aplicar stemmer y lematizador a la base de testeo\n",
        "re_limp=[]\n",
        "\n",
        "for i in tqdm(text_test['text']):\n",
        "    re_limp.append(limpiar(i))\n",
        "\n",
        "## Stemmer\n",
        "stemmer = Stemmer(lenguaje='español')\n",
        "\n",
        "corpus_stem=[]\n",
        "for i in tqdm(re_limp):\n",
        "    stem = stem_texto(i, stemmer=stemmer)\n",
        "    corpus_stem.append(stem)\n",
        "\n",
        "test_stem = test.drop(['text'], axis=1)\n",
        "test_stem['text'] = corpus_stem\n",
        "\n",
        "## Lematizador\n",
        "lematizador = LematizadorSpacy('es')\n",
        "\n",
        "corpus_lem =[]\n",
        "for i in tqdm(re_limp):\n",
        "    lem = lematizar_texto(i, lematizador=lematizador)\n",
        "    corpus_lem.append(lem)\n",
        "\n",
        "\n",
        "test_lem = test.drop(['text'], axis=1)\n",
        "test_lem['text'] = corpus_lem\n",
        "\n",
        "test_lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-w6fe9eE6jL"
      },
      "outputs": [],
      "source": [
        "# Base de entrenamiento\n",
        "train_tweets = train_lem['text'].tolist()\n",
        "train_labels = train_lem['name'].tolist()\n",
        "\n",
        "# Base de testeo\n",
        "test_tweets = test_lem['text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cu1X7aoFNd3",
        "outputId": "89745410-5e27-4107-b84f-0b1523bd79da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<10849x18117 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 159157 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "cv = CountVectorizer()\n",
        "cv.fit_transform(train_tweets + test_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZTpjGkVGWy8"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfTransformer()\n",
        "\n",
        "train_features = tfidf.fit_transform(cv.transform(train_tweets))\n",
        "test_features = tfidf.transform(cv.transform(test_tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDN7V1RXzJ5y",
        "outputId": "3d6edf40-c09f-4906-b253-bb5826ec9175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En entrenamiento, el número de filas son: 9349 y el número de columnas son:  18117\n"
          ]
        }
      ],
      "source": [
        "print(\"En entrenamiento, el número de filas son:\", train_features.shape[0], \"y el número de columnas son: \", train_features.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjsPmWh22XUB",
        "outputId": "3a5189da-5c79-453f-da5a-50678447b44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En testeo, el número de filas son: 1500 y el número de columnas son:  18117\n"
          ]
        }
      ],
      "source": [
        "print(\"En testeo, el número de filas son:\", test_features.shape[0], \"y el número de columnas son: \", test_features.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xC0WmCO-_vr"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(train_lem, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KV5Uyoha_ScH",
        "outputId": "c60b88e5-0f81-400e-e9e8-1c16d83cfa5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id   name  \\\n",
              "6443  fa93b1f78b7c3887a5c18b33  Petro   \n",
              "5846  d992ebc2dab434d7ed625298  Lopez   \n",
              "6972  717bcfeedf544aec375fa254  Lopez   \n",
              "251   d7209aab3fa9cb67c45057d6  Uribe   \n",
              "6950  7059c1122bdbb937b88d0716  Petro   \n",
              "...                        ...    ...   \n",
              "5734  41b9786eec413d9980cba113  Lopez   \n",
              "5191  0ee30ae87235377ba0ef9ee6  Uribe   \n",
              "5390  55536c9007d96a131e4b7e88  Petro   \n",
              "860   de130ff13da2f4f4aa1823ef  Petro   \n",
              "7270  839eb75e8ba3501cea4e950e  Uribe   \n",
              "\n",
              "                                                   text  \n",
              "6443  ataque caudio electoral trapero quitar ojo jov...  \n",
              "5846                               juntoscuidamosbogota  \n",
              "6972  querer cambiar él cara bogota actor sistema di...  \n",
              "251   dias intervencion integral fuerzapublico logro...  \n",
              "6950      minuto entrevistar gustavo gomez caracolradio  \n",
              "...                                                 ...  \n",
              "5734  este contrato social jovenesalau apostar cumpl...  \n",
              "5191  dejar leer entrevista yaya blondie andres muje...  \n",
              "5390   captainpolombia ivanducar este gente representar  \n",
              "860   interés especulacion inmobiliario llevar const...  \n",
              "7270  doler partido aurita garcia gomez ayudo solida...  \n",
              "\n",
              "[7479 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f2cb10f-1c3c-415d-99fc-3b4f48c39ebe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6443</th>\n",
              "      <td>fa93b1f78b7c3887a5c18b33</td>\n",
              "      <td>Petro</td>\n",
              "      <td>ataque caudio electoral trapero quitar ojo jov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5846</th>\n",
              "      <td>d992ebc2dab434d7ed625298</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>juntoscuidamosbogota</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6972</th>\n",
              "      <td>717bcfeedf544aec375fa254</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>querer cambiar él cara bogota actor sistema di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>d7209aab3fa9cb67c45057d6</td>\n",
              "      <td>Uribe</td>\n",
              "      <td>dias intervencion integral fuerzapublico logro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6950</th>\n",
              "      <td>7059c1122bdbb937b88d0716</td>\n",
              "      <td>Petro</td>\n",
              "      <td>minuto entrevistar gustavo gomez caracolradio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5734</th>\n",
              "      <td>41b9786eec413d9980cba113</td>\n",
              "      <td>Lopez</td>\n",
              "      <td>este contrato social jovenesalau apostar cumpl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>0ee30ae87235377ba0ef9ee6</td>\n",
              "      <td>Uribe</td>\n",
              "      <td>dejar leer entrevista yaya blondie andres muje...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>55536c9007d96a131e4b7e88</td>\n",
              "      <td>Petro</td>\n",
              "      <td>captainpolombia ivanducar este gente representar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>de130ff13da2f4f4aa1823ef</td>\n",
              "      <td>Petro</td>\n",
              "      <td>interés especulacion inmobiliario llevar const...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>839eb75e8ba3501cea4e950e</td>\n",
              "      <td>Uribe</td>\n",
              "      <td>doler partido aurita garcia gomez ayudo solida...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7479 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f2cb10f-1c3c-415d-99fc-3b4f48c39ebe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f2cb10f-1c3c-415d-99fc-3b4f48c39ebe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f2cb10f-1c3c-415d-99fc-3b4f48c39ebe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crear base de entrenamiento\n",
        "\n",
        "Para tener una proxy del desempeño de los modelos planteados, se crea una base de testeo a partir de la base de entrenamiento. Sobre esta base se realiza una primera evaluación para ver el desempeño del modelo antes de subirlo a la plataforma Kaggle."
      ],
      "metadata": {
        "id": "YBnYnLJWNXOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfJsWAD--_rS"
      },
      "outputs": [],
      "source": [
        "# Base de entrenamiento\n",
        "train_tweets1 = train_data['text'].tolist()\n",
        "train_labels1 = train_data['name'].tolist()\n",
        "\n",
        "# Base de testeo\n",
        "test_tweets1 = test_data['text'].tolist()\n",
        "test_labels1 = test_data['name'].tolist()\n",
        "\n",
        "\n",
        "cv = CountVectorizer()\n",
        "cv.fit_transform(train_tweets1 + test_tweets1)\n",
        "\n",
        "\n",
        "tfidf = TfidfTransformer()\n",
        "\n",
        "train_features1 = tfidf.fit_transform(cv.transform(train_tweets1))\n",
        "test_features1 = tfidf.transform(cv.transform(test_tweets1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos"
      ],
      "metadata": {
        "id": "d8qDM-R1NmfD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nBNG-vlwPAv"
      },
      "source": [
        "## Logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSvDKuMfonvz"
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "y_pred_logit = clf.predict(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6qzZzG3o0L_"
      },
      "outputs": [],
      "source": [
        "test['name'] = y_pred_logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JlF-3HOgpBT3",
        "outputId": "9c2bad44-b767-4426-9a9c-36045e5841b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f6a2ce5f-c9a6-47df-bf4f-49273aa829ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f4f09622255e9d9d76251b4</td>\n",
              "      <td>Lopez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aefd318f57227e4053f64191</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d1eb53be99fa263c10911af9</td>\n",
              "      <td>Petro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bb65250f1ff7582e4380a9c9</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0017570ee84b80e1c3e10218</td>\n",
              "      <td>Lopez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>4d1dc06d6ca8d0da93ceb42a</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>db282aa075d8ffb4dc9d72ae</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>afaac0a39ec1ea5f58308407</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>262b591834494af862ed6f09</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>617192c47672548910aca070</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6a2ce5f-c9a6-47df-bf4f-49273aa829ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6a2ce5f-c9a6-47df-bf4f-49273aa829ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6a2ce5f-c9a6-47df-bf4f-49273aa829ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                            id   name\n",
              "0     6f4f09622255e9d9d76251b4  Lopez\n",
              "1     aefd318f57227e4053f64191  Uribe\n",
              "2     d1eb53be99fa263c10911af9  Petro\n",
              "3     bb65250f1ff7582e4380a9c9  Uribe\n",
              "4     0017570ee84b80e1c3e10218  Lopez\n",
              "...                        ...    ...\n",
              "1495  4d1dc06d6ca8d0da93ceb42a  Uribe\n",
              "1496  db282aa075d8ffb4dc9d72ae  Uribe\n",
              "1497  afaac0a39ec1ea5f58308407  Uribe\n",
              "1498  262b591834494af862ed6f09  Uribe\n",
              "1499  617192c47672548910aca070  Uribe\n",
              "\n",
              "[1500 rows x 2 columns]"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = test.drop(['text'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRjE8H_ypVRy"
      },
      "outputs": [],
      "source": [
        "test.to_csv('modelo_logit.csv', index=False)\n",
        "test = test.drop(['name'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVgob_tfqj_k"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f35YP79grT2F"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "y_pred_RF = clf.predict(test_features)\n",
        "\n",
        "test['name'] = y_pred_RF\n",
        "\n",
        "test.to_csv('modelo_RF.csv', index=False)\n",
        "test = test.drop(['name'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsNc4l5PsDJh"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "train_features1_dense = train_features1.toarray()\n",
        "test_features1_dense = test_features1.toarray()\n",
        "\n",
        "model = LinearDiscriminantAnalysis()\n",
        "\n",
        "model.fit(train_features1_dense, train_labels1)\n",
        "\n",
        "y_pred = model.predict(test_features1_dense)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "accuracy = accuracy_score(test_labels1, y_pred)\n",
        "print(\"Precisión del modelo:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pppANrqHpPjL",
        "outputId": "a26a75b0-98f8-4f43-8428-a2fbdafcb4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.7197860962566844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_dense = train_features.toarray()\n",
        "test_features_dense = test_features.toarray()\n",
        "\n",
        "# Entrenar modelo\n",
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(train_features_dense, train_labels)\n",
        "\n",
        "# Predecir las categorías de los tweets en el conjunto de prueba\n",
        "y_pred = model.predict(test_features_dense)\n",
        "\n",
        "test['name'] = y_pred\n",
        "test1 = test\n",
        "test1 = test1.drop(['text'], axis=1)\n",
        "test1.to_csv('modelo_LDA.csv', index=False)\n",
        "test = test.drop(['name'], axis=1)"
      ],
      "metadata": {
        "id": "thy0dn3DyFBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWL6QMCctzwb"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA410nk_t_Dl"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Entrenar modelo de Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(train_features, train_labels)\n",
        "\n",
        "# Predecir las categorías de los tweets en el conjunto de prueba\n",
        "y_pred = nb.predict(test_features)\n",
        "\n",
        "test['name'] = y_pred\n",
        "test.to_csv('modelo_NB.csv', index=False)\n",
        "test = test.drop(['name'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-IaI2n1mmx5"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxePFG4wH2tK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels1)\n",
        "\n",
        "# Convertir las etiquetas en enteros utilizando el LabelEncoder\n",
        "train_labels_encoded1 = le.transform(train_labels1)\n",
        "train_features_dense1 = train_features1.toarray()\n",
        "train_labels_encoded1 = np.array(train_labels_encoded1)\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWYHRUV_H3Eq",
        "outputId": "f8b593c9-a871-427b-e80c-fbd9c58688f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 0.7033 - accuracy: 0.9291 - val_loss: 1.0323 - val_accuracy: 0.7928\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 45s 240ms/step - loss: 0.6863 - accuracy: 0.9382 - val_loss: 0.9895 - val_accuracy: 0.8035\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 45s 239ms/step - loss: 0.6920 - accuracy: 0.9326 - val_loss: 1.0047 - val_accuracy: 0.8182\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 44s 237ms/step - loss: 0.6832 - accuracy: 0.9365 - val_loss: 1.0169 - val_accuracy: 0.8082\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 40s 215ms/step - loss: 0.7002 - accuracy: 0.9325 - val_loss: 1.0388 - val_accuracy: 0.8061\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 40s 213ms/step - loss: 0.7116 - accuracy: 0.9325 - val_loss: 1.0097 - val_accuracy: 0.8102\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 41s 219ms/step - loss: 0.6754 - accuracy: 0.9375 - val_loss: 1.0178 - val_accuracy: 0.8021\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 0.6746 - accuracy: 0.9395 - val_loss: 1.0094 - val_accuracy: 0.8035\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 42s 222ms/step - loss: 0.6916 - accuracy: 0.9310 - val_loss: 1.0295 - val_accuracy: 0.7981\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 42s 223ms/step - loss: 0.6996 - accuracy: 0.9351 - val_loss: 1.0615 - val_accuracy: 0.7981\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 39s 211ms/step - loss: 0.6869 - accuracy: 0.9367 - val_loss: 1.0215 - val_accuracy: 0.8115\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 41s 220ms/step - loss: 0.6997 - accuracy: 0.9321 - val_loss: 1.0449 - val_accuracy: 0.8028\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 41s 217ms/step - loss: 0.6840 - accuracy: 0.9415 - val_loss: 1.0087 - val_accuracy: 0.8108\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 39s 210ms/step - loss: 0.6853 - accuracy: 0.9348 - val_loss: 1.0371 - val_accuracy: 0.7988\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 50s 269ms/step - loss: 0.7009 - accuracy: 0.9343 - val_loss: 1.0324 - val_accuracy: 0.8021\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 44s 238ms/step - loss: 0.6926 - accuracy: 0.9351 - val_loss: 0.9870 - val_accuracy: 0.8209\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 45s 240ms/step - loss: 0.6918 - accuracy: 0.9362 - val_loss: 1.0208 - val_accuracy: 0.8075\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 43s 231ms/step - loss: 0.6993 - accuracy: 0.9345 - val_loss: 1.0423 - val_accuracy: 0.7948\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 42s 226ms/step - loss: 0.6757 - accuracy: 0.9408 - val_loss: 1.0214 - val_accuracy: 0.8102\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 42s 225ms/step - loss: 0.6707 - accuracy: 0.9398 - val_loss: 1.0206 - val_accuracy: 0.7888\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 44s 237ms/step - loss: 0.6812 - accuracy: 0.9300 - val_loss: 1.0343 - val_accuracy: 0.8075\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 43s 232ms/step - loss: 0.7015 - accuracy: 0.9343 - val_loss: 1.0288 - val_accuracy: 0.8068\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 44s 237ms/step - loss: 0.6653 - accuracy: 0.9420 - val_loss: 1.0223 - val_accuracy: 0.8015\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 41s 217ms/step - loss: 0.6684 - accuracy: 0.9370 - val_loss: 1.0109 - val_accuracy: 0.8061\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 42s 225ms/step - loss: 0.6818 - accuracy: 0.9400 - val_loss: 1.0570 - val_accuracy: 0.8021\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 44s 237ms/step - loss: 0.6880 - accuracy: 0.9363 - val_loss: 1.0566 - val_accuracy: 0.7955\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 42s 224ms/step - loss: 0.6898 - accuracy: 0.9355 - val_loss: 1.0306 - val_accuracy: 0.8135\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 40s 214ms/step - loss: 0.6706 - accuracy: 0.9440 - val_loss: 1.1635 - val_accuracy: 0.7761\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 49s 265ms/step - loss: 0.6743 - accuracy: 0.9388 - val_loss: 0.9813 - val_accuracy: 0.8095\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 42s 224ms/step - loss: 0.6892 - accuracy: 0.9370 - val_loss: 1.0777 - val_accuracy: 0.7901\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 41s 218ms/step - loss: 0.6887 - accuracy: 0.9335 - val_loss: 1.0662 - val_accuracy: 0.7955\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 40s 215ms/step - loss: 0.6825 - accuracy: 0.9380 - val_loss: 1.0652 - val_accuracy: 0.7968\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 42s 227ms/step - loss: 0.6835 - accuracy: 0.9405 - val_loss: 1.0349 - val_accuracy: 0.7928\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 42s 223ms/step - loss: 0.6702 - accuracy: 0.9420 - val_loss: 1.0190 - val_accuracy: 0.8061\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 39s 209ms/step - loss: 0.6782 - accuracy: 0.9360 - val_loss: 1.0332 - val_accuracy: 0.7934\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 41s 218ms/step - loss: 0.6782 - accuracy: 0.9408 - val_loss: 1.0679 - val_accuracy: 0.7988\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 43s 231ms/step - loss: 0.6740 - accuracy: 0.9373 - val_loss: 1.0105 - val_accuracy: 0.8102\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 43s 228ms/step - loss: 0.6777 - accuracy: 0.9346 - val_loss: 1.0848 - val_accuracy: 0.7908\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 40s 215ms/step - loss: 0.6991 - accuracy: 0.9346 - val_loss: 1.0534 - val_accuracy: 0.7981\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 41s 218ms/step - loss: 0.6913 - accuracy: 0.9372 - val_loss: 1.0354 - val_accuracy: 0.8082\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 42s 225ms/step - loss: 0.6815 - accuracy: 0.9400 - val_loss: 1.0416 - val_accuracy: 0.8061\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 0.6611 - accuracy: 0.9428 - val_loss: 1.0141 - val_accuracy: 0.8021\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 41s 221ms/step - loss: 0.6555 - accuracy: 0.9433 - val_loss: 1.0212 - val_accuracy: 0.7975\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 50s 268ms/step - loss: 0.6755 - accuracy: 0.9368 - val_loss: 1.0176 - val_accuracy: 0.8142\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 43s 230ms/step - loss: 0.6642 - accuracy: 0.9412 - val_loss: 1.0372 - val_accuracy: 0.8035\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 41s 220ms/step - loss: 0.6612 - accuracy: 0.9400 - val_loss: 1.0190 - val_accuracy: 0.8075\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 43s 229ms/step - loss: 0.6737 - accuracy: 0.9405 - val_loss: 1.0281 - val_accuracy: 0.8082\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 43s 229ms/step - loss: 0.6843 - accuracy: 0.9402 - val_loss: 1.0775 - val_accuracy: 0.7934\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 42s 225ms/step - loss: 0.6551 - accuracy: 0.9460 - val_loss: 1.0435 - val_accuracy: 0.8048\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 39s 208ms/step - loss: 0.6811 - accuracy: 0.9325 - val_loss: 1.0291 - val_accuracy: 0.8122\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 40s 213ms/step - loss: 0.7129 - accuracy: 0.9328 - val_loss: 1.0382 - val_accuracy: 0.8108\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 0.6885 - accuracy: 0.9387 - val_loss: 1.0128 - val_accuracy: 0.8222\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 0.6601 - accuracy: 0.9412 - val_loss: 0.9948 - val_accuracy: 0.8108\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 0.6669 - accuracy: 0.9397 - val_loss: 0.9859 - val_accuracy: 0.8235\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 0.6733 - accuracy: 0.9388 - val_loss: 1.0148 - val_accuracy: 0.8055\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 40s 213ms/step - loss: 0.6668 - accuracy: 0.9380 - val_loss: 1.0635 - val_accuracy: 0.7961\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 0.6798 - accuracy: 0.9377 - val_loss: 1.0710 - val_accuracy: 0.7928\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 40s 214ms/step - loss: 0.6869 - accuracy: 0.9353 - val_loss: 1.0438 - val_accuracy: 0.8142\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 47s 254ms/step - loss: 0.6897 - accuracy: 0.9377 - val_loss: 1.0294 - val_accuracy: 0.8128\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 0.6718 - accuracy: 0.9407 - val_loss: 1.0802 - val_accuracy: 0.7868\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda480955b0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(512, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(train_features_dense1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(test_features_dense1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvIDTHj9H3CB",
        "outputId": "53a5ba54-ab38-4cde-ab4e-976f145982b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 2s 32ms/step - loss: 0.9819 - accuracy: 0.8209\n",
            "Exactitud en el conjunto de prueba: 0.8208556175231934\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(test_features_dense1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9U_clEzIzF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c56870-1cb2-4201-d265-130acda8133b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 39s 204ms/step - loss: 1.9324 - accuracy: 0.4148 - val_loss: 1.1767 - val_accuracy: 0.4813\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 36s 193ms/step - loss: 1.2483 - accuracy: 0.5875 - val_loss: 1.2863 - val_accuracy: 0.6070\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 37s 200ms/step - loss: 1.3137 - accuracy: 0.6121 - val_loss: 1.3292 - val_accuracy: 0.6136\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 36s 194ms/step - loss: 1.3254 - accuracy: 0.6201 - val_loss: 1.3454 - val_accuracy: 0.6156\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.3324 - accuracy: 0.6286 - val_loss: 1.3772 - val_accuracy: 0.6003\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.3398 - accuracy: 0.6400 - val_loss: 1.3548 - val_accuracy: 0.6096\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 37s 195ms/step - loss: 1.3300 - accuracy: 0.6420 - val_loss: 1.3419 - val_accuracy: 0.6143\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.3211 - accuracy: 0.6395 - val_loss: 1.3539 - val_accuracy: 0.6197\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 37s 195ms/step - loss: 1.3243 - accuracy: 0.6458 - val_loss: 1.3572 - val_accuracy: 0.6290\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 38s 201ms/step - loss: 1.3072 - accuracy: 0.6518 - val_loss: 1.3779 - val_accuracy: 0.6370\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.3196 - accuracy: 0.6513 - val_loss: 1.3659 - val_accuracy: 0.6250\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.2978 - accuracy: 0.6564 - val_loss: 1.3391 - val_accuracy: 0.6277\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.3119 - accuracy: 0.6604 - val_loss: 1.3807 - val_accuracy: 0.6230\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.3139 - accuracy: 0.6605 - val_loss: 1.3563 - val_accuracy: 0.6410\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.2931 - accuracy: 0.6634 - val_loss: 1.3559 - val_accuracy: 0.6277\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 1.2807 - accuracy: 0.6637 - val_loss: 1.3337 - val_accuracy: 0.6424\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 37s 201ms/step - loss: 1.2790 - accuracy: 0.6727 - val_loss: 1.3311 - val_accuracy: 0.6310\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 37s 198ms/step - loss: 1.2853 - accuracy: 0.6679 - val_loss: 1.3520 - val_accuracy: 0.6370\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.2990 - accuracy: 0.6751 - val_loss: 1.3491 - val_accuracy: 0.6457\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.2896 - accuracy: 0.6724 - val_loss: 1.3517 - val_accuracy: 0.6297\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.2999 - accuracy: 0.6662 - val_loss: 1.3537 - val_accuracy: 0.6417\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.2975 - accuracy: 0.6752 - val_loss: 1.3325 - val_accuracy: 0.6484\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.2588 - accuracy: 0.6883 - val_loss: 1.3342 - val_accuracy: 0.6404\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.2798 - accuracy: 0.6858 - val_loss: 1.3468 - val_accuracy: 0.6571\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 37s 199ms/step - loss: 1.2852 - accuracy: 0.6824 - val_loss: 1.3239 - val_accuracy: 0.6437\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 39s 207ms/step - loss: 1.3003 - accuracy: 0.6759 - val_loss: 1.3602 - val_accuracy: 0.6544\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 36s 192ms/step - loss: 1.2866 - accuracy: 0.6886 - val_loss: 1.3675 - val_accuracy: 0.6604\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.3006 - accuracy: 0.7020 - val_loss: 1.3749 - val_accuracy: 0.6638\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.3071 - accuracy: 0.6926 - val_loss: 1.4011 - val_accuracy: 0.6798\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.3239 - accuracy: 0.6993 - val_loss: 1.3749 - val_accuracy: 0.6698\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 39s 207ms/step - loss: 1.3158 - accuracy: 0.7147 - val_loss: 1.4106 - val_accuracy: 0.6430\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.3138 - accuracy: 0.7276 - val_loss: 1.3648 - val_accuracy: 0.6725\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.3138 - accuracy: 0.7319 - val_loss: 1.3713 - val_accuracy: 0.7199\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 36s 194ms/step - loss: 1.3053 - accuracy: 0.7496 - val_loss: 1.3809 - val_accuracy: 0.7293\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.3186 - accuracy: 0.7419 - val_loss: 1.4003 - val_accuracy: 0.7440\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 36s 194ms/step - loss: 1.3201 - accuracy: 0.7561 - val_loss: 1.3829 - val_accuracy: 0.7426\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.3114 - accuracy: 0.7652 - val_loss: 1.3927 - val_accuracy: 0.7547\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.3272 - accuracy: 0.7797 - val_loss: 1.3913 - val_accuracy: 0.7734\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 37s 198ms/step - loss: 1.3043 - accuracy: 0.7882 - val_loss: 1.3828 - val_accuracy: 0.7680\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.2966 - accuracy: 0.7934 - val_loss: 1.3558 - val_accuracy: 0.7767\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.2963 - accuracy: 0.8028 - val_loss: 1.3855 - val_accuracy: 0.7908\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.2870 - accuracy: 0.8118 - val_loss: 1.3891 - val_accuracy: 0.7761\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 1.2845 - accuracy: 0.8202 - val_loss: 1.3544 - val_accuracy: 0.8035\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 37s 200ms/step - loss: 1.2810 - accuracy: 0.8275 - val_loss: 1.3283 - val_accuracy: 0.8015\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 1.2636 - accuracy: 0.8288 - val_loss: 1.3521 - val_accuracy: 0.7948\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.2800 - accuracy: 0.8299 - val_loss: 1.3535 - val_accuracy: 0.7888\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.2715 - accuracy: 0.8319 - val_loss: 1.3530 - val_accuracy: 0.8021\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.2688 - accuracy: 0.8312 - val_loss: 1.3402 - val_accuracy: 0.8015\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 38s 201ms/step - loss: 1.2564 - accuracy: 0.8372 - val_loss: 1.3502 - val_accuracy: 0.8035\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 39s 207ms/step - loss: 1.2554 - accuracy: 0.8414 - val_loss: 1.3491 - val_accuracy: 0.7988\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 37s 197ms/step - loss: 1.2671 - accuracy: 0.8422 - val_loss: 1.3456 - val_accuracy: 0.8008\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 39s 206ms/step - loss: 1.2581 - accuracy: 0.8487 - val_loss: 1.3415 - val_accuracy: 0.8041\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.2730 - accuracy: 0.8392 - val_loss: 1.3710 - val_accuracy: 0.7934\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 1.2686 - accuracy: 0.8472 - val_loss: 1.3364 - val_accuracy: 0.8108\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 1.2424 - accuracy: 0.8514 - val_loss: 1.3574 - val_accuracy: 0.7948\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 37s 195ms/step - loss: 1.2658 - accuracy: 0.8441 - val_loss: 1.3575 - val_accuracy: 0.7941\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.2518 - accuracy: 0.8533 - val_loss: 1.3464 - val_accuracy: 0.7948\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 37s 197ms/step - loss: 1.2717 - accuracy: 0.8446 - val_loss: 1.3457 - val_accuracy: 0.8309\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 38s 203ms/step - loss: 1.2438 - accuracy: 0.8579 - val_loss: 1.3287 - val_accuracy: 0.8142\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 36s 193ms/step - loss: 1.2425 - accuracy: 0.8553 - val_loss: 1.3338 - val_accuracy: 0.8195\n",
            "59/59 [==============================] - 1s 22ms/step - loss: 1.3118 - accuracy: 0.8176\n",
            "Exactitud en el conjunto de prueba: 0.8176470398902893\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels1)\n",
        "\n",
        "# Convertir las etiquetas en enteros utilizando el LabelEncoder\n",
        "train_labels_encoded1 = le.transform(train_labels1)\n",
        "train_features_dense1 = train_features1.toarray()\n",
        "train_labels_encoded1 = np.array(train_labels_encoded1)\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(512, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(train_features_dense1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(test_features_dense1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(512, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(train_features_dense1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(test_features_dense1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHO80bPec3nQ",
        "outputId": "92cd677e-4bb7-482b-bcbd-c72564b4c496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 50s 265ms/step - loss: 1.4298 - accuracy: 0.6196 - val_loss: 1.1380 - val_accuracy: 0.7353\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 36s 193ms/step - loss: 1.1414 - accuracy: 0.7510 - val_loss: 1.1923 - val_accuracy: 0.7400\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 1.1627 - accuracy: 0.7602 - val_loss: 1.2001 - val_accuracy: 0.7634\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.1735 - accuracy: 0.7690 - val_loss: 1.2478 - val_accuracy: 0.7567\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 1.1723 - accuracy: 0.7780 - val_loss: 1.2104 - val_accuracy: 0.7594\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 36s 195ms/step - loss: 1.1747 - accuracy: 0.7814 - val_loss: 1.2655 - val_accuracy: 0.7433\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 38s 206ms/step - loss: 1.2049 - accuracy: 0.7747 - val_loss: 1.2131 - val_accuracy: 0.7660\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 37s 197ms/step - loss: 1.1881 - accuracy: 0.7881 - val_loss: 1.2555 - val_accuracy: 0.7814\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 37s 196ms/step - loss: 1.2133 - accuracy: 0.7847 - val_loss: 1.2785 - val_accuracy: 0.7627\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.2075 - accuracy: 0.7824 - val_loss: 1.2760 - val_accuracy: 0.7567\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 36s 194ms/step - loss: 1.1939 - accuracy: 0.7907 - val_loss: 1.2615 - val_accuracy: 0.7741\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.1946 - accuracy: 0.7901 - val_loss: 1.3294 - val_accuracy: 0.7580\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 39s 211ms/step - loss: 1.2030 - accuracy: 0.7929 - val_loss: 1.3173 - val_accuracy: 0.7640\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 46s 246ms/step - loss: 1.1878 - accuracy: 0.7907 - val_loss: 1.3412 - val_accuracy: 0.7634\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 39s 208ms/step - loss: 1.1942 - accuracy: 0.7988 - val_loss: 1.3485 - val_accuracy: 0.7426\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 36s 194ms/step - loss: 1.1703 - accuracy: 0.8049 - val_loss: 1.3156 - val_accuracy: 0.7614\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 37s 200ms/step - loss: 1.1865 - accuracy: 0.8041 - val_loss: 1.2540 - val_accuracy: 0.7828\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 36s 193ms/step - loss: 1.1871 - accuracy: 0.8009 - val_loss: 1.3112 - val_accuracy: 0.7654\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.1835 - accuracy: 0.8003 - val_loss: 1.2995 - val_accuracy: 0.7654\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 36s 193ms/step - loss: 1.1827 - accuracy: 0.8081 - val_loss: 1.3057 - val_accuracy: 0.7627\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 39s 207ms/step - loss: 1.1865 - accuracy: 0.8058 - val_loss: 1.3295 - val_accuracy: 0.7701\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 41s 222ms/step - loss: 1.1785 - accuracy: 0.8063 - val_loss: 1.2686 - val_accuracy: 0.7680\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 37s 198ms/step - loss: 1.1638 - accuracy: 0.8053 - val_loss: 1.3167 - val_accuracy: 0.7654\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.1735 - accuracy: 0.8070 - val_loss: 1.3468 - val_accuracy: 0.7707\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 39s 208ms/step - loss: 1.1433 - accuracy: 0.8126 - val_loss: 1.3161 - val_accuracy: 0.7640\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 1.1561 - accuracy: 0.8100 - val_loss: 1.3270 - val_accuracy: 0.7574\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 37s 200ms/step - loss: 1.1300 - accuracy: 0.8182 - val_loss: 1.2916 - val_accuracy: 0.7841\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 36s 193ms/step - loss: 1.1254 - accuracy: 0.8245 - val_loss: 1.2970 - val_accuracy: 0.7767\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 39s 207ms/step - loss: 1.1227 - accuracy: 0.8235 - val_loss: 1.2953 - val_accuracy: 0.7741\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 1.1230 - accuracy: 0.8203 - val_loss: 1.2440 - val_accuracy: 0.7741\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 36s 194ms/step - loss: 1.1077 - accuracy: 0.8210 - val_loss: 1.2770 - val_accuracy: 0.7794\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 48s 257ms/step - loss: 1.0923 - accuracy: 0.8263 - val_loss: 1.2325 - val_accuracy: 0.7687\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 41s 219ms/step - loss: 1.0766 - accuracy: 0.8267 - val_loss: 1.2646 - val_accuracy: 0.7687\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 39s 209ms/step - loss: 1.0747 - accuracy: 0.8288 - val_loss: 1.2493 - val_accuracy: 0.7741\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 38s 205ms/step - loss: 1.0596 - accuracy: 0.8355 - val_loss: 1.2781 - val_accuracy: 0.7734\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 39s 209ms/step - loss: 1.0272 - accuracy: 0.8409 - val_loss: 1.2736 - val_accuracy: 0.7741\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 40s 211ms/step - loss: 1.0418 - accuracy: 0.8372 - val_loss: 1.2734 - val_accuracy: 0.7707\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 40s 214ms/step - loss: 1.0103 - accuracy: 0.8437 - val_loss: 1.1779 - val_accuracy: 0.7975\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 1.0041 - accuracy: 0.8431 - val_loss: 1.2079 - val_accuracy: 0.7841\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 39s 211ms/step - loss: 1.0076 - accuracy: 0.8477 - val_loss: 1.2485 - val_accuracy: 0.7761\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 39s 211ms/step - loss: 1.0032 - accuracy: 0.8446 - val_loss: 1.2561 - val_accuracy: 0.7767\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 0.9855 - accuracy: 0.8494 - val_loss: 1.1737 - val_accuracy: 0.7801\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 0.9547 - accuracy: 0.8522 - val_loss: 1.1832 - val_accuracy: 0.7754\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 40s 212ms/step - loss: 0.9591 - accuracy: 0.8561 - val_loss: 1.2184 - val_accuracy: 0.7647\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 39s 211ms/step - loss: 0.9401 - accuracy: 0.8583 - val_loss: 1.1508 - val_accuracy: 0.7941\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 38s 204ms/step - loss: 0.9399 - accuracy: 0.8583 - val_loss: 1.1556 - val_accuracy: 0.7821\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 39s 210ms/step - loss: 0.9404 - accuracy: 0.8541 - val_loss: 1.1743 - val_accuracy: 0.7874\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 40s 216ms/step - loss: 0.9185 - accuracy: 0.8623 - val_loss: 1.1445 - val_accuracy: 0.7761\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 0.9019 - accuracy: 0.8608 - val_loss: 1.1140 - val_accuracy: 0.7861\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 40s 213ms/step - loss: 0.8919 - accuracy: 0.8663 - val_loss: 1.1768 - val_accuracy: 0.7848\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 47s 250ms/step - loss: 0.8809 - accuracy: 0.8720 - val_loss: 1.1448 - val_accuracy: 0.7881\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 43s 228ms/step - loss: 0.8934 - accuracy: 0.8665 - val_loss: 1.1413 - val_accuracy: 0.7774\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 41s 221ms/step - loss: 0.8631 - accuracy: 0.8735 - val_loss: 1.1237 - val_accuracy: 0.7928\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 40s 213ms/step - loss: 0.8395 - accuracy: 0.8765 - val_loss: 1.1311 - val_accuracy: 0.7861\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 39s 207ms/step - loss: 0.8484 - accuracy: 0.8751 - val_loss: 1.1499 - val_accuracy: 0.7834\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 39s 209ms/step - loss: 0.8412 - accuracy: 0.8755 - val_loss: 1.0976 - val_accuracy: 0.7834\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 40s 213ms/step - loss: 0.8270 - accuracy: 0.8807 - val_loss: 1.1122 - val_accuracy: 0.7968\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 41s 218ms/step - loss: 0.8293 - accuracy: 0.8812 - val_loss: 1.0869 - val_accuracy: 0.7908\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 38s 202ms/step - loss: 0.8131 - accuracy: 0.8873 - val_loss: 1.0942 - val_accuracy: 0.7834\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 40s 214ms/step - loss: 0.7875 - accuracy: 0.8885 - val_loss: 1.1239 - val_accuracy: 0.7794\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 1.1001 - accuracy: 0.7925\n",
            "Exactitud en el conjunto de prueba: 0.792513370513916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(216, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(train_features_dense1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(test_features_dense1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9h2r2VWc3kX",
        "outputId": "99d8919b-5722-466b-cda5-e8f44137b331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 14s 65ms/step - loss: 1.2267 - accuracy: 0.5842 - val_loss: 1.0893 - val_accuracy: 0.7326\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 1.0583 - accuracy: 0.7630 - val_loss: 1.0592 - val_accuracy: 0.7547\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 1.0327 - accuracy: 0.7799 - val_loss: 1.0498 - val_accuracy: 0.7587\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 1.0157 - accuracy: 0.7882 - val_loss: 1.0354 - val_accuracy: 0.7988\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 1.0065 - accuracy: 0.7964 - val_loss: 1.0516 - val_accuracy: 0.7787\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9937 - accuracy: 0.8008 - val_loss: 1.0345 - val_accuracy: 0.7828\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9848 - accuracy: 0.8133 - val_loss: 1.0462 - val_accuracy: 0.7841\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9774 - accuracy: 0.8187 - val_loss: 1.0496 - val_accuracy: 0.7707\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.9777 - accuracy: 0.8123 - val_loss: 1.0417 - val_accuracy: 0.7921\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9709 - accuracy: 0.8177 - val_loss: 1.0449 - val_accuracy: 0.7888\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9625 - accuracy: 0.8213 - val_loss: 1.0570 - val_accuracy: 0.7741\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.9652 - accuracy: 0.8193 - val_loss: 1.0319 - val_accuracy: 0.7854\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.9578 - accuracy: 0.8217 - val_loss: 1.0714 - val_accuracy: 0.7854\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9429 - accuracy: 0.8278 - val_loss: 1.0977 - val_accuracy: 0.7627\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9457 - accuracy: 0.8302 - val_loss: 1.0893 - val_accuracy: 0.7848\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.9495 - accuracy: 0.8280 - val_loss: 1.0720 - val_accuracy: 0.7848\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.9515 - accuracy: 0.8305 - val_loss: 1.0706 - val_accuracy: 0.8028\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.9447 - accuracy: 0.8315 - val_loss: 1.0474 - val_accuracy: 0.7841\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9257 - accuracy: 0.8400 - val_loss: 1.0936 - val_accuracy: 0.7821\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 9s 50ms/step - loss: 0.9419 - accuracy: 0.8335 - val_loss: 1.1181 - val_accuracy: 0.7727\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9315 - accuracy: 0.8432 - val_loss: 1.0645 - val_accuracy: 0.8028\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9119 - accuracy: 0.8487 - val_loss: 1.0429 - val_accuracy: 0.7961\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.9242 - accuracy: 0.8409 - val_loss: 1.0572 - val_accuracy: 0.7934\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.9178 - accuracy: 0.8441 - val_loss: 1.0577 - val_accuracy: 0.8021\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.9156 - accuracy: 0.8497 - val_loss: 1.0462 - val_accuracy: 0.8015\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8926 - accuracy: 0.8526 - val_loss: 1.0664 - val_accuracy: 0.7955\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.9168 - accuracy: 0.8454 - val_loss: 1.0866 - val_accuracy: 0.7908\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.9106 - accuracy: 0.8471 - val_loss: 1.0958 - val_accuracy: 0.7941\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8999 - accuracy: 0.8551 - val_loss: 1.0861 - val_accuracy: 0.7834\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8988 - accuracy: 0.8539 - val_loss: 1.1032 - val_accuracy: 0.7707\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 9s 50ms/step - loss: 0.9042 - accuracy: 0.8501 - val_loss: 1.1214 - val_accuracy: 0.7828\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8996 - accuracy: 0.8527 - val_loss: 1.0684 - val_accuracy: 0.7941\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8746 - accuracy: 0.8609 - val_loss: 1.1200 - val_accuracy: 0.7868\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.8970 - accuracy: 0.8548 - val_loss: 1.1185 - val_accuracy: 0.7754\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.8830 - accuracy: 0.8564 - val_loss: 1.1273 - val_accuracy: 0.7687\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8693 - accuracy: 0.8650 - val_loss: 1.1172 - val_accuracy: 0.7727\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8818 - accuracy: 0.8636 - val_loss: 1.1325 - val_accuracy: 0.7787\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.8728 - accuracy: 0.8626 - val_loss: 1.1242 - val_accuracy: 0.7727\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.8589 - accuracy: 0.8706 - val_loss: 1.1044 - val_accuracy: 0.7774\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8591 - accuracy: 0.8665 - val_loss: 1.0925 - val_accuracy: 0.8028\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8574 - accuracy: 0.8673 - val_loss: 1.1155 - val_accuracy: 0.7888\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.8411 - accuracy: 0.8736 - val_loss: 1.1223 - val_accuracy: 0.7734\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8554 - accuracy: 0.8728 - val_loss: 1.1093 - val_accuracy: 0.7781\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.8556 - accuracy: 0.8676 - val_loss: 1.1003 - val_accuracy: 0.7781\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.8488 - accuracy: 0.8703 - val_loss: 1.1316 - val_accuracy: 0.7701\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 9s 51ms/step - loss: 0.8265 - accuracy: 0.8750 - val_loss: 1.1357 - val_accuracy: 0.7727\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8292 - accuracy: 0.8765 - val_loss: 1.0980 - val_accuracy: 0.7774\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8286 - accuracy: 0.8832 - val_loss: 1.0957 - val_accuracy: 0.7667\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.8097 - accuracy: 0.8830 - val_loss: 1.0687 - val_accuracy: 0.7761\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.8161 - accuracy: 0.8802 - val_loss: 1.1348 - val_accuracy: 0.7807\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8198 - accuracy: 0.8761 - val_loss: 1.0956 - val_accuracy: 0.7888\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8023 - accuracy: 0.8847 - val_loss: 1.0815 - val_accuracy: 0.7894\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 0.7887 - accuracy: 0.8843 - val_loss: 1.1071 - val_accuracy: 0.7821\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 0.7851 - accuracy: 0.8890 - val_loss: 1.1060 - val_accuracy: 0.7814\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7924 - accuracy: 0.8870 - val_loss: 1.0692 - val_accuracy: 0.7928\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.7704 - accuracy: 0.8942 - val_loss: 1.0848 - val_accuracy: 0.7961\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.7584 - accuracy: 0.8947 - val_loss: 1.0449 - val_accuracy: 0.7861\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.7716 - accuracy: 0.8885 - val_loss: 1.0578 - val_accuracy: 0.7861\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7608 - accuracy: 0.8964 - val_loss: 1.0746 - val_accuracy: 0.7774\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7323 - accuracy: 0.8992 - val_loss: 1.0432 - val_accuracy: 0.7901\n",
            "59/59 [==============================] - 1s 10ms/step - loss: 1.0185 - accuracy: 0.7920\n",
            "Exactitud en el conjunto de prueba: 0.7919785976409912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(216, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2CTQnXHc3hx",
        "outputId": "902780cf-892a-45be-eb82-cc834c976b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 6.5945 - accuracy: 0.5221 - val_loss: 3.3038 - val_accuracy: 0.6210\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 1.9619 - accuracy: 0.8533 - val_loss: 1.6018 - val_accuracy: 0.8088\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.9007 - accuracy: 0.9687 - val_loss: 1.0982 - val_accuracy: 0.8028\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.5542 - accuracy: 0.9830 - val_loss: 1.0024 - val_accuracy: 0.7881\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.5126 - accuracy: 0.9769 - val_loss: 1.1374 - val_accuracy: 0.7500\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.5822 - accuracy: 0.9696 - val_loss: 1.3363 - val_accuracy: 0.7620\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.7355 - accuracy: 0.9629 - val_loss: 1.4960 - val_accuracy: 0.7520\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.7125 - accuracy: 0.9666 - val_loss: 1.3890 - val_accuracy: 0.7674\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.6094 - accuracy: 0.9764 - val_loss: 1.2666 - val_accuracy: 0.7567\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.4876 - accuracy: 0.9818 - val_loss: 1.1562 - val_accuracy: 0.7607\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.3877 - accuracy: 0.9870 - val_loss: 0.9889 - val_accuracy: 0.7734\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.3196 - accuracy: 0.9886 - val_loss: 0.9662 - val_accuracy: 0.7807\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.2968 - accuracy: 0.9901 - val_loss: 1.0135 - val_accuracy: 0.7674\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.3158 - accuracy: 0.9870 - val_loss: 1.0452 - val_accuracy: 0.7734\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.3287 - accuracy: 0.9868 - val_loss: 1.1216 - val_accuracy: 0.7567\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.3176 - accuracy: 0.9853 - val_loss: 1.1007 - val_accuracy: 0.7721\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.3467 - accuracy: 0.9816 - val_loss: 1.0880 - val_accuracy: 0.7687\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.2875 - accuracy: 0.9886 - val_loss: 1.0846 - val_accuracy: 0.7567\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 0.2486 - accuracy: 0.9891 - val_loss: 0.9783 - val_accuracy: 0.7701\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1974 - accuracy: 0.9950 - val_loss: 0.9124 - val_accuracy: 0.7761\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.1695 - accuracy: 0.9945 - val_loss: 0.9424 - val_accuracy: 0.7594\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.1698 - accuracy: 0.9928 - val_loss: 0.9336 - val_accuracy: 0.7600\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.1864 - accuracy: 0.9898 - val_loss: 1.0154 - val_accuracy: 0.7533\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.1854 - accuracy: 0.9898 - val_loss: 1.0160 - val_accuracy: 0.7547\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.2025 - accuracy: 0.9866 - val_loss: 1.1350 - val_accuracy: 0.7473\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.2151 - accuracy: 0.9871 - val_loss: 1.1361 - val_accuracy: 0.7433\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.2103 - accuracy: 0.9870 - val_loss: 1.2125 - val_accuracy: 0.7473\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1820 - accuracy: 0.9916 - val_loss: 1.1263 - val_accuracy: 0.7533\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.1603 - accuracy: 0.9921 - val_loss: 1.0441 - val_accuracy: 0.7567\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.1393 - accuracy: 0.9943 - val_loss: 0.9784 - val_accuracy: 0.7580\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1225 - accuracy: 0.9952 - val_loss: 0.9566 - val_accuracy: 0.7667\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1128 - accuracy: 0.9948 - val_loss: 0.9358 - val_accuracy: 0.7701\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 0.1165 - accuracy: 0.9940 - val_loss: 1.0298 - val_accuracy: 0.7467\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.1398 - accuracy: 0.9886 - val_loss: 1.1962 - val_accuracy: 0.7386\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1667 - accuracy: 0.9863 - val_loss: 1.2551 - val_accuracy: 0.7400\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.1850 - accuracy: 0.9863 - val_loss: 1.2587 - val_accuracy: 0.7567\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 9s 50ms/step - loss: 0.1734 - accuracy: 0.9895 - val_loss: 1.1902 - val_accuracy: 0.7487\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.1470 - accuracy: 0.9928 - val_loss: 1.2325 - val_accuracy: 0.7440\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.1383 - accuracy: 0.9926 - val_loss: 1.0782 - val_accuracy: 0.7680\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.1215 - accuracy: 0.9950 - val_loss: 1.0301 - val_accuracy: 0.7660\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.1168 - accuracy: 0.9945 - val_loss: 1.0133 - val_accuracy: 0.7680\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1090 - accuracy: 0.9957 - val_loss: 0.9915 - val_accuracy: 0.7727\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.1143 - accuracy: 0.9920 - val_loss: 1.0322 - val_accuracy: 0.7674\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.1345 - accuracy: 0.9901 - val_loss: 1.0930 - val_accuracy: 0.7540\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.1461 - accuracy: 0.9885 - val_loss: 1.2708 - val_accuracy: 0.7326\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1519 - accuracy: 0.9881 - val_loss: 1.2504 - val_accuracy: 0.7594\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.1511 - accuracy: 0.9903 - val_loss: 1.3073 - val_accuracy: 0.7373\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.1325 - accuracy: 0.9935 - val_loss: 1.2916 - val_accuracy: 0.7493\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.1176 - accuracy: 0.9945 - val_loss: 1.2106 - val_accuracy: 0.7460\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1258 - accuracy: 0.9901 - val_loss: 1.1991 - val_accuracy: 0.7346\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1270 - accuracy: 0.9906 - val_loss: 1.1503 - val_accuracy: 0.7426\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 0.1400 - accuracy: 0.9896 - val_loss: 1.1240 - val_accuracy: 0.7560\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.1275 - accuracy: 0.9918 - val_loss: 1.0577 - val_accuracy: 0.7574\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.1189 - accuracy: 0.9938 - val_loss: 1.1085 - val_accuracy: 0.7507\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1148 - accuracy: 0.9926 - val_loss: 1.3003 - val_accuracy: 0.7340\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.1185 - accuracy: 0.9923 - val_loss: 1.2149 - val_accuracy: 0.7333\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.1384 - accuracy: 0.9873 - val_loss: 1.2392 - val_accuracy: 0.7413\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.1287 - accuracy: 0.9913 - val_loss: 1.2268 - val_accuracy: 0.7453\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.1291 - accuracy: 0.9910 - val_loss: 1.1017 - val_accuracy: 0.7567\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.1253 - accuracy: 0.9905 - val_loss: 1.2105 - val_accuracy: 0.7453\n",
            "59/59 [==============================] - 1s 11ms/step - loss: 1.1825 - accuracy: 0.7626\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.762566864490509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(216, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3I6Jkppc3fK",
        "outputId": "0c3f1d8e-d635-4c85-8548-c95e430e2afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 20s 95ms/step - loss: 5.9796 - accuracy: 0.5604 - val_loss: 5.6251 - val_accuracy: 0.5943\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 2.3833 - accuracy: 0.8188 - val_loss: 1.7605 - val_accuracy: 0.8088\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 1.1502 - accuracy: 0.9622 - val_loss: 1.2800 - val_accuracy: 0.8148\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.7848 - accuracy: 0.9794 - val_loss: 1.1071 - val_accuracy: 0.8115\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.6651 - accuracy: 0.9788 - val_loss: 1.0920 - val_accuracy: 0.8001\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 12s 64ms/step - loss: 0.6753 - accuracy: 0.9736 - val_loss: 1.1705 - val_accuracy: 0.8015\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.7530 - accuracy: 0.9666 - val_loss: 1.4585 - val_accuracy: 0.7627\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.9496 - accuracy: 0.9539 - val_loss: 1.5910 - val_accuracy: 0.7674\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 13s 67ms/step - loss: 1.0408 - accuracy: 0.9557 - val_loss: 1.7478 - val_accuracy: 0.7654\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 1.1234 - accuracy: 0.9529 - val_loss: 1.8844 - val_accuracy: 0.7567\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 1.2272 - accuracy: 0.9507 - val_loss: 1.9021 - val_accuracy: 0.7513\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 1.1791 - accuracy: 0.9589 - val_loss: 1.7504 - val_accuracy: 0.7734\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 1.0825 - accuracy: 0.9649 - val_loss: 1.6240 - val_accuracy: 0.7727\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 12s 64ms/step - loss: 0.9966 - accuracy: 0.9649 - val_loss: 1.6680 - val_accuracy: 0.7660\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 1.0656 - accuracy: 0.9622 - val_loss: 1.6997 - val_accuracy: 0.7667\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 12s 64ms/step - loss: 1.1030 - accuracy: 0.9609 - val_loss: 1.7996 - val_accuracy: 0.7620\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 1.1225 - accuracy: 0.9611 - val_loss: 2.0121 - val_accuracy: 0.7366\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 13s 69ms/step - loss: 1.0435 - accuracy: 0.9636 - val_loss: 1.6752 - val_accuracy: 0.7580\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 9s 49ms/step - loss: 1.0310 - accuracy: 0.9632 - val_loss: 1.6764 - val_accuracy: 0.7620\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 1.0233 - accuracy: 0.9572 - val_loss: 1.7608 - val_accuracy: 0.7727\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 1.0553 - accuracy: 0.9606 - val_loss: 1.8922 - val_accuracy: 0.7513\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 1.0645 - accuracy: 0.9621 - val_loss: 1.7943 - val_accuracy: 0.7567\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.9878 - accuracy: 0.9686 - val_loss: 1.6075 - val_accuracy: 0.7754\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9371 - accuracy: 0.9667 - val_loss: 1.6354 - val_accuracy: 0.7694\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9834 - accuracy: 0.9641 - val_loss: 1.6632 - val_accuracy: 0.7734\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.9921 - accuracy: 0.9632 - val_loss: 1.6965 - val_accuracy: 0.7734\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.9714 - accuracy: 0.9646 - val_loss: 1.6150 - val_accuracy: 0.7721\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9310 - accuracy: 0.9674 - val_loss: 1.5159 - val_accuracy: 0.7761\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.9338 - accuracy: 0.9679 - val_loss: 1.5904 - val_accuracy: 0.7674\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.9570 - accuracy: 0.9627 - val_loss: 1.6414 - val_accuracy: 0.7607\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.9580 - accuracy: 0.9651 - val_loss: 1.6145 - val_accuracy: 0.7587\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9251 - accuracy: 0.9642 - val_loss: 1.6180 - val_accuracy: 0.7627\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9237 - accuracy: 0.9644 - val_loss: 1.6907 - val_accuracy: 0.7647\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.9310 - accuracy: 0.9667 - val_loss: 1.6088 - val_accuracy: 0.7687\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9094 - accuracy: 0.9677 - val_loss: 1.4786 - val_accuracy: 0.7841\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8387 - accuracy: 0.9748 - val_loss: 1.6077 - val_accuracy: 0.7580\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8610 - accuracy: 0.9639 - val_loss: 1.6436 - val_accuracy: 0.7440\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.8566 - accuracy: 0.9687 - val_loss: 1.5661 - val_accuracy: 0.7527\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8442 - accuracy: 0.9672 - val_loss: 1.5241 - val_accuracy: 0.7560\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.8773 - accuracy: 0.9646 - val_loss: 1.5452 - val_accuracy: 0.7747\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.9080 - accuracy: 0.9612 - val_loss: 1.5167 - val_accuracy: 0.7754\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.9077 - accuracy: 0.9646 - val_loss: 1.5880 - val_accuracy: 0.7774\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8550 - accuracy: 0.9713 - val_loss: 1.3765 - val_accuracy: 0.7754\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8294 - accuracy: 0.9679 - val_loss: 1.4334 - val_accuracy: 0.7787\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.8154 - accuracy: 0.9697 - val_loss: 1.4605 - val_accuracy: 0.7627\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.7868 - accuracy: 0.9706 - val_loss: 1.4325 - val_accuracy: 0.7734\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7795 - accuracy: 0.9724 - val_loss: 1.4246 - val_accuracy: 0.7607\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7836 - accuracy: 0.9661 - val_loss: 1.4839 - val_accuracy: 0.7727\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.8070 - accuracy: 0.9676 - val_loss: 1.4797 - val_accuracy: 0.7734\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.7917 - accuracy: 0.9708 - val_loss: 1.5726 - val_accuracy: 0.7620\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8372 - accuracy: 0.9664 - val_loss: 1.6060 - val_accuracy: 0.7654\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8410 - accuracy: 0.9686 - val_loss: 1.5820 - val_accuracy: 0.7620\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.8610 - accuracy: 0.9631 - val_loss: 1.5707 - val_accuracy: 0.7500\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 14s 73ms/step - loss: 0.8678 - accuracy: 0.9651 - val_loss: 1.5004 - val_accuracy: 0.7660\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8514 - accuracy: 0.9669 - val_loss: 1.5180 - val_accuracy: 0.7747\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.8202 - accuracy: 0.9706 - val_loss: 1.4163 - val_accuracy: 0.7667\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8184 - accuracy: 0.9652 - val_loss: 1.4648 - val_accuracy: 0.7614\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.7854 - accuracy: 0.9692 - val_loss: 1.4501 - val_accuracy: 0.7694\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7730 - accuracy: 0.9691 - val_loss: 1.7049 - val_accuracy: 0.7326\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7623 - accuracy: 0.9706 - val_loss: 1.7413 - val_accuracy: 0.7266\n",
            "59/59 [==============================] - 1s 10ms/step - loss: 1.4544 - accuracy: 0.7807\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.7807486653327942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(216, input_dim=train_features_dense1.shape[1], activation='softmax', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEi2XcBcc3dl",
        "outputId": "ef3ce988-e85b-49b9-907a-060e9d9d97e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 12s 61ms/step - loss: 1.2647 - accuracy: 0.3879 - val_loss: 1.1513 - val_accuracy: 0.3616\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 1.1651 - accuracy: 0.3861 - val_loss: 1.1994 - val_accuracy: 0.3623\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 1.1890 - accuracy: 0.4423 - val_loss: 1.1893 - val_accuracy: 0.6303\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 1.1326 - accuracy: 0.7053 - val_loss: 1.1447 - val_accuracy: 0.7654\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 1.0239 - accuracy: 0.7135 - val_loss: 1.0734 - val_accuracy: 0.7841\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.9248 - accuracy: 0.7234 - val_loss: 1.0060 - val_accuracy: 0.8055\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.8425 - accuracy: 0.7471 - val_loss: 0.9702 - val_accuracy: 0.8108\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.8018 - accuracy: 0.7590 - val_loss: 0.9164 - val_accuracy: 0.7961\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.7804 - accuracy: 0.7515 - val_loss: 0.9065 - val_accuracy: 0.7961\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.7686 - accuracy: 0.7630 - val_loss: 0.8712 - val_accuracy: 0.8055\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.7545 - accuracy: 0.7737 - val_loss: 0.8540 - val_accuracy: 0.8015\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.7426 - accuracy: 0.7762 - val_loss: 0.8437 - val_accuracy: 0.7961\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7224 - accuracy: 0.7919 - val_loss: 0.8326 - val_accuracy: 0.7908\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7327 - accuracy: 0.7867 - val_loss: 0.8083 - val_accuracy: 0.8041\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.7181 - accuracy: 0.7944 - val_loss: 0.8271 - val_accuracy: 0.7841\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7106 - accuracy: 0.7994 - val_loss: 0.8063 - val_accuracy: 0.7934\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7028 - accuracy: 0.8046 - val_loss: 0.8000 - val_accuracy: 0.7988\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.6915 - accuracy: 0.8160 - val_loss: 0.7823 - val_accuracy: 0.7975\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.6929 - accuracy: 0.8093 - val_loss: 0.8009 - val_accuracy: 0.7981\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7000 - accuracy: 0.8066 - val_loss: 0.7833 - val_accuracy: 0.7928\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6966 - accuracy: 0.8053 - val_loss: 0.7893 - val_accuracy: 0.7874\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.6797 - accuracy: 0.8232 - val_loss: 0.7800 - val_accuracy: 0.7861\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.6880 - accuracy: 0.8170 - val_loss: 0.8435 - val_accuracy: 0.7727\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6881 - accuracy: 0.8207 - val_loss: 0.7648 - val_accuracy: 0.7874\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 12s 66ms/step - loss: 0.6641 - accuracy: 0.8250 - val_loss: 0.7521 - val_accuracy: 0.7955\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.6702 - accuracy: 0.8263 - val_loss: 0.7717 - val_accuracy: 0.7908\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.6835 - accuracy: 0.8163 - val_loss: 0.7806 - val_accuracy: 0.7881\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6566 - accuracy: 0.8287 - val_loss: 0.7605 - val_accuracy: 0.7888\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.6753 - accuracy: 0.8258 - val_loss: 0.7805 - val_accuracy: 0.7901\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.6697 - accuracy: 0.8273 - val_loss: 0.7737 - val_accuracy: 0.7881\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.6648 - accuracy: 0.8213 - val_loss: 0.7878 - val_accuracy: 0.7821\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6688 - accuracy: 0.8230 - val_loss: 0.7801 - val_accuracy: 0.7868\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6627 - accuracy: 0.8292 - val_loss: 0.7947 - val_accuracy: 0.7841\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.6617 - accuracy: 0.8282 - val_loss: 0.7769 - val_accuracy: 0.7861\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.6691 - accuracy: 0.8280 - val_loss: 0.7884 - val_accuracy: 0.7814\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6599 - accuracy: 0.8329 - val_loss: 0.7634 - val_accuracy: 0.8028\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6396 - accuracy: 0.8310 - val_loss: 0.7726 - val_accuracy: 0.7975\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.6438 - accuracy: 0.8324 - val_loss: 0.7841 - val_accuracy: 0.7881\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6414 - accuracy: 0.8385 - val_loss: 0.8223 - val_accuracy: 0.7988\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6543 - accuracy: 0.8304 - val_loss: 0.8151 - val_accuracy: 0.7848\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.6335 - accuracy: 0.8405 - val_loss: 0.8102 - val_accuracy: 0.7961\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.6567 - accuracy: 0.8370 - val_loss: 0.7936 - val_accuracy: 0.7921\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6764 - accuracy: 0.8277 - val_loss: 0.8246 - val_accuracy: 0.7888\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6569 - accuracy: 0.8382 - val_loss: 0.8318 - val_accuracy: 0.7787\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.6498 - accuracy: 0.8349 - val_loss: 0.8053 - val_accuracy: 0.7868\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.6419 - accuracy: 0.8359 - val_loss: 0.7932 - val_accuracy: 0.7914\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6352 - accuracy: 0.8400 - val_loss: 0.8004 - val_accuracy: 0.7894\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6292 - accuracy: 0.8477 - val_loss: 0.8408 - val_accuracy: 0.7774\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 13s 72ms/step - loss: 0.6564 - accuracy: 0.8374 - val_loss: 0.8531 - val_accuracy: 0.7841\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.6441 - accuracy: 0.8467 - val_loss: 0.8650 - val_accuracy: 0.7814\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6476 - accuracy: 0.8359 - val_loss: 0.8468 - val_accuracy: 0.7868\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6667 - accuracy: 0.8365 - val_loss: 0.8350 - val_accuracy: 0.7894\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6381 - accuracy: 0.8452 - val_loss: 0.8693 - val_accuracy: 0.7814\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.6409 - accuracy: 0.8492 - val_loss: 0.8576 - val_accuracy: 0.7834\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6534 - accuracy: 0.8400 - val_loss: 0.8712 - val_accuracy: 0.7801\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6490 - accuracy: 0.8454 - val_loss: 0.8415 - val_accuracy: 0.7874\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6303 - accuracy: 0.8538 - val_loss: 0.8853 - val_accuracy: 0.7767\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.6325 - accuracy: 0.8524 - val_loss: 0.8434 - val_accuracy: 0.7888\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6304 - accuracy: 0.8432 - val_loss: 0.8767 - val_accuracy: 0.7861\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6446 - accuracy: 0.8464 - val_loss: 0.8970 - val_accuracy: 0.7921\n",
            "59/59 [==============================] - 1s 10ms/step - loss: 0.8921 - accuracy: 0.7947\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.7946524024009705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(216, input_dim=train_features_dense1.shape[1], activation=tf.nn.elu, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wpogKegc3az",
        "outputId": "bfa0bf31-9e01-405c-9498-7db6e0dc113f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 13s 65ms/step - loss: 5.0349 - accuracy: 0.5743 - val_loss: 5.3970 - val_accuracy: 0.6150\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 1.7066 - accuracy: 0.9056 - val_loss: 1.5873 - val_accuracy: 0.7988\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 0.8992 - accuracy: 0.9783 - val_loss: 1.1982 - val_accuracy: 0.7914\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6869 - accuracy: 0.9763 - val_loss: 1.2168 - val_accuracy: 0.7781\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.7717 - accuracy: 0.9604 - val_loss: 1.6382 - val_accuracy: 0.7393\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.9502 - accuracy: 0.9462 - val_loss: 1.7976 - val_accuracy: 0.7473\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 1.0661 - accuracy: 0.9489 - val_loss: 1.7166 - val_accuracy: 0.7553\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.9505 - accuracy: 0.9646 - val_loss: 1.5822 - val_accuracy: 0.7687\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 11s 62ms/step - loss: 0.8385 - accuracy: 0.9641 - val_loss: 1.7536 - val_accuracy: 0.7433\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.8675 - accuracy: 0.9584 - val_loss: 1.7475 - val_accuracy: 0.7493\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.8838 - accuracy: 0.9594 - val_loss: 1.6759 - val_accuracy: 0.7614\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.9251 - accuracy: 0.9594 - val_loss: 1.6546 - val_accuracy: 0.7513\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.8508 - accuracy: 0.9636 - val_loss: 1.6285 - val_accuracy: 0.7507\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7561 - accuracy: 0.9684 - val_loss: 1.5129 - val_accuracy: 0.7507\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7401 - accuracy: 0.9664 - val_loss: 1.5187 - val_accuracy: 0.7594\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.7624 - accuracy: 0.9667 - val_loss: 1.5319 - val_accuracy: 0.7460\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7346 - accuracy: 0.9694 - val_loss: 1.4623 - val_accuracy: 0.7634\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.7239 - accuracy: 0.9661 - val_loss: 1.4994 - val_accuracy: 0.7520\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.7202 - accuracy: 0.9662 - val_loss: 1.5476 - val_accuracy: 0.7380\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.6812 - accuracy: 0.9741 - val_loss: 1.4079 - val_accuracy: 0.7654\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6601 - accuracy: 0.9726 - val_loss: 1.3807 - val_accuracy: 0.7754\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6881 - accuracy: 0.9664 - val_loss: 1.4797 - val_accuracy: 0.7707\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.6996 - accuracy: 0.9684 - val_loss: 1.4608 - val_accuracy: 0.7721\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 10s 52ms/step - loss: 0.6922 - accuracy: 0.9642 - val_loss: 1.6543 - val_accuracy: 0.7487\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7069 - accuracy: 0.9718 - val_loss: 1.5843 - val_accuracy: 0.7426\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7374 - accuracy: 0.9672 - val_loss: 1.6121 - val_accuracy: 0.7527\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6985 - accuracy: 0.9736 - val_loss: 1.5379 - val_accuracy: 0.7620\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 10s 51ms/step - loss: 0.6769 - accuracy: 0.9699 - val_loss: 1.6718 - val_accuracy: 0.7500\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 12s 66ms/step - loss: 0.7098 - accuracy: 0.9647 - val_loss: 1.5328 - val_accuracy: 0.7647\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7326 - accuracy: 0.9661 - val_loss: 1.5698 - val_accuracy: 0.7627\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6594 - accuracy: 0.9746 - val_loss: 1.4702 - val_accuracy: 0.7567\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 11s 59ms/step - loss: 0.6010 - accuracy: 0.9769 - val_loss: 1.5323 - val_accuracy: 0.7386\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.6104 - accuracy: 0.9721 - val_loss: 1.5098 - val_accuracy: 0.7594\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6670 - accuracy: 0.9694 - val_loss: 1.5087 - val_accuracy: 0.7614\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.7071 - accuracy: 0.9681 - val_loss: 1.5087 - val_accuracy: 0.7687\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.7398 - accuracy: 0.9657 - val_loss: 1.6279 - val_accuracy: 0.7607\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 11s 56ms/step - loss: 0.7372 - accuracy: 0.9669 - val_loss: 1.6291 - val_accuracy: 0.7594\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6813 - accuracy: 0.9716 - val_loss: 1.4934 - val_accuracy: 0.7701\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 11s 62ms/step - loss: 0.6263 - accuracy: 0.9743 - val_loss: 1.4265 - val_accuracy: 0.7493\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.5925 - accuracy: 0.9779 - val_loss: 1.5334 - val_accuracy: 0.7574\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.6069 - accuracy: 0.9723 - val_loss: 1.5675 - val_accuracy: 0.7587\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 12s 61ms/step - loss: 0.6332 - accuracy: 0.9744 - val_loss: 1.4271 - val_accuracy: 0.7794\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6183 - accuracy: 0.9724 - val_loss: 1.4539 - val_accuracy: 0.7473\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6644 - accuracy: 0.9672 - val_loss: 1.5449 - val_accuracy: 0.7660\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 11s 58ms/step - loss: 0.6908 - accuracy: 0.9714 - val_loss: 1.6050 - val_accuracy: 0.7567\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 11s 57ms/step - loss: 0.6842 - accuracy: 0.9718 - val_loss: 1.5026 - val_accuracy: 0.7640\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6385 - accuracy: 0.9696 - val_loss: 1.5918 - val_accuracy: 0.7701\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.7027 - accuracy: 0.9697 - val_loss: 1.6807 - val_accuracy: 0.7520\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 11s 60ms/step - loss: 0.6811 - accuracy: 0.9723 - val_loss: 1.5685 - val_accuracy: 0.7594\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 10s 55ms/step - loss: 0.6596 - accuracy: 0.9734 - val_loss: 1.5943 - val_accuracy: 0.7547\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 12s 63ms/step - loss: 0.6307 - accuracy: 0.9721 - val_loss: 1.4902 - val_accuracy: 0.7627\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6497 - accuracy: 0.9696 - val_loss: 1.5442 - val_accuracy: 0.7487\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 12s 64ms/step - loss: 0.6973 - accuracy: 0.9681 - val_loss: 1.5898 - val_accuracy: 0.7587\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 13s 71ms/step - loss: 0.6813 - accuracy: 0.9731 - val_loss: 1.4463 - val_accuracy: 0.7687\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 10s 56ms/step - loss: 0.6159 - accuracy: 0.9739 - val_loss: 1.5555 - val_accuracy: 0.7487\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 12s 62ms/step - loss: 0.6213 - accuracy: 0.9699 - val_loss: 1.4887 - val_accuracy: 0.7533\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.6292 - accuracy: 0.9756 - val_loss: 1.5364 - val_accuracy: 0.7620\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 11s 62ms/step - loss: 0.6466 - accuracy: 0.9696 - val_loss: 1.5365 - val_accuracy: 0.7540\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 10s 53ms/step - loss: 0.6507 - accuracy: 0.9744 - val_loss: 1.5326 - val_accuracy: 0.7620\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 11s 61ms/step - loss: 0.5839 - accuracy: 0.9768 - val_loss: 1.5691 - val_accuracy: 0.7553\n",
            "59/59 [==============================] - 1s 11ms/step - loss: 1.5154 - accuracy: 0.7754\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.7754010558128357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, input_dim=train_features_dense1.shape[1], activation=tf.nn.elu, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD_jZqbmc3YA",
        "outputId": "56dcb276-b2d0-41be-933e-dd87317c1c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 21s 27ms/step - loss: 3.6765 - accuracy: 0.5430 - val_loss: 2.3438 - val_accuracy: 0.6745\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 1.4397 - accuracy: 0.8471 - val_loss: 1.2515 - val_accuracy: 0.8175\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.7910 - accuracy: 0.9644 - val_loss: 1.0189 - val_accuracy: 0.8142\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 4s 23ms/step - loss: 0.5499 - accuracy: 0.9858 - val_loss: 0.8979 - val_accuracy: 0.8048\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 4s 22ms/step - loss: 0.4394 - accuracy: 0.9868 - val_loss: 0.8968 - val_accuracy: 0.7814\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.4158 - accuracy: 0.9831 - val_loss: 1.0452 - val_accuracy: 0.7587\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.4641 - accuracy: 0.9738 - val_loss: 1.1088 - val_accuracy: 0.7707\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 4s 23ms/step - loss: 0.5422 - accuracy: 0.9686 - val_loss: 1.2609 - val_accuracy: 0.7654\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 4s 21ms/step - loss: 0.5841 - accuracy: 0.9687 - val_loss: 1.2887 - val_accuracy: 0.7640\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6254 - accuracy: 0.9609 - val_loss: 1.3877 - val_accuracy: 0.7594\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6507 - accuracy: 0.9649 - val_loss: 1.3161 - val_accuracy: 0.7640\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 4s 23ms/step - loss: 0.6408 - accuracy: 0.9689 - val_loss: 1.3279 - val_accuracy: 0.7640\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 4s 20ms/step - loss: 0.6358 - accuracy: 0.9704 - val_loss: 1.3994 - val_accuracy: 0.7587\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6389 - accuracy: 0.9711 - val_loss: 1.5353 - val_accuracy: 0.7386\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6355 - accuracy: 0.9682 - val_loss: 1.5242 - val_accuracy: 0.7493\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 5s 25ms/step - loss: 0.6868 - accuracy: 0.9656 - val_loss: 1.5034 - val_accuracy: 0.7634\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 4s 19ms/step - loss: 0.6762 - accuracy: 0.9662 - val_loss: 1.4600 - val_accuracy: 0.7627\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6732 - accuracy: 0.9691 - val_loss: 1.4865 - val_accuracy: 0.7540\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6650 - accuracy: 0.9692 - val_loss: 1.4204 - val_accuracy: 0.7627\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 5s 25ms/step - loss: 0.6689 - accuracy: 0.9686 - val_loss: 1.4952 - val_accuracy: 0.7553\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6417 - accuracy: 0.9704 - val_loss: 1.4622 - val_accuracy: 0.7614\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6228 - accuracy: 0.9726 - val_loss: 1.4705 - val_accuracy: 0.7667\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.6095 - accuracy: 0.9682 - val_loss: 1.4698 - val_accuracy: 0.7607\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 5s 27ms/step - loss: 0.6217 - accuracy: 0.9699 - val_loss: 1.4994 - val_accuracy: 0.7533\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5981 - accuracy: 0.9758 - val_loss: 1.4272 - val_accuracy: 0.7406\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6196 - accuracy: 0.9694 - val_loss: 1.4112 - val_accuracy: 0.7574\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.6443 - accuracy: 0.9704 - val_loss: 1.5333 - val_accuracy: 0.7707\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 5s 27ms/step - loss: 0.6355 - accuracy: 0.9708 - val_loss: 1.5963 - val_accuracy: 0.7386\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.6044 - accuracy: 0.9711 - val_loss: 1.3943 - val_accuracy: 0.7734\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5913 - accuracy: 0.9738 - val_loss: 1.4425 - val_accuracy: 0.7533\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5926 - accuracy: 0.9711 - val_loss: 1.4844 - val_accuracy: 0.7507\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 5s 26ms/step - loss: 0.5916 - accuracy: 0.9746 - val_loss: 1.4311 - val_accuracy: 0.7660\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5841 - accuracy: 0.9714 - val_loss: 1.3644 - val_accuracy: 0.7567\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.5670 - accuracy: 0.9736 - val_loss: 1.4429 - val_accuracy: 0.7567\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5659 - accuracy: 0.9731 - val_loss: 1.5841 - val_accuracy: 0.7440\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 5s 26ms/step - loss: 0.5798 - accuracy: 0.9729 - val_loss: 1.4189 - val_accuracy: 0.7493\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5878 - accuracy: 0.9704 - val_loss: 1.4586 - val_accuracy: 0.7587\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5816 - accuracy: 0.9716 - val_loss: 1.4280 - val_accuracy: 0.7507\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5743 - accuracy: 0.9769 - val_loss: 1.3877 - val_accuracy: 0.7594\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 5s 26ms/step - loss: 0.5546 - accuracy: 0.9731 - val_loss: 1.3219 - val_accuracy: 0.7640\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5358 - accuracy: 0.9763 - val_loss: 1.4096 - val_accuracy: 0.7587\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.5566 - accuracy: 0.9718 - val_loss: 1.5757 - val_accuracy: 0.7453\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 4s 20ms/step - loss: 0.6125 - accuracy: 0.9631 - val_loss: 1.5644 - val_accuracy: 0.7500\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 5s 24ms/step - loss: 0.6006 - accuracy: 0.9709 - val_loss: 1.4750 - val_accuracy: 0.7607\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5601 - accuracy: 0.9753 - val_loss: 1.4509 - val_accuracy: 0.7660\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.5583 - accuracy: 0.9743 - val_loss: 1.3664 - val_accuracy: 0.7654\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 4s 21ms/step - loss: 0.5206 - accuracy: 0.9774 - val_loss: 1.4772 - val_accuracy: 0.7540\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 4s 23ms/step - loss: 0.5414 - accuracy: 0.9751 - val_loss: 1.3927 - val_accuracy: 0.7520\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.5383 - accuracy: 0.9731 - val_loss: 1.5828 - val_accuracy: 0.7480\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.5772 - accuracy: 0.9656 - val_loss: 1.5490 - val_accuracy: 0.7527\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 4s 22ms/step - loss: 0.6044 - accuracy: 0.9684 - val_loss: 1.4966 - val_accuracy: 0.7607\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 4s 22ms/step - loss: 0.5742 - accuracy: 0.9724 - val_loss: 1.4518 - val_accuracy: 0.7473\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 0.5443 - accuracy: 0.9763 - val_loss: 1.4425 - val_accuracy: 0.7520\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5142 - accuracy: 0.9759 - val_loss: 1.4055 - val_accuracy: 0.7540\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 4s 23ms/step - loss: 0.5104 - accuracy: 0.9749 - val_loss: 1.4629 - val_accuracy: 0.7467\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 4s 22ms/step - loss: 0.5094 - accuracy: 0.9741 - val_loss: 1.3605 - val_accuracy: 0.7540\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5394 - accuracy: 0.9689 - val_loss: 1.4176 - val_accuracy: 0.7560\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 0.5552 - accuracy: 0.9741 - val_loss: 1.5030 - val_accuracy: 0.7614\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 5s 24ms/step - loss: 0.5550 - accuracy: 0.9744 - val_loss: 1.4062 - val_accuracy: 0.7640\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 4s 20ms/step - loss: 0.5461 - accuracy: 0.9721 - val_loss: 1.3657 - val_accuracy: 0.7647\n",
            "59/59 [==============================] - 0s 5ms/step - loss: 1.4639 - accuracy: 0.7733\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.7732620239257812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(152, input_dim=train_features_dense1.shape[1], activation=tf.nn.elu, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(64, input_dim=train_features_dense1.shape[1], activation=tf.nn.elu, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMy74N-S4Lqy",
        "outputId": "43156150-d5e1-45ff-e9e6-41ad9fdcf287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 8s 40ms/step - loss: 3.3305 - accuracy: 0.6156 - val_loss: 2.6974 - val_accuracy: 0.7774\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 2.2616 - accuracy: 0.8700 - val_loss: 2.4218 - val_accuracy: 0.7774\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 7s 40ms/step - loss: 1.6806 - accuracy: 0.9489 - val_loss: 1.9423 - val_accuracy: 0.7854\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 1.2525 - accuracy: 0.9701 - val_loss: 1.7232 - val_accuracy: 0.7761\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 0.9991 - accuracy: 0.9751 - val_loss: 1.5020 - val_accuracy: 0.7848\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 8s 40ms/step - loss: 0.8667 - accuracy: 0.9738 - val_loss: 1.7272 - val_accuracy: 0.7239\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 0.8949 - accuracy: 0.9627 - val_loss: 1.6865 - val_accuracy: 0.7513\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.9132 - accuracy: 0.9661 - val_loss: 1.5724 - val_accuracy: 0.7647\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 0.8450 - accuracy: 0.9728 - val_loss: 1.6162 - val_accuracy: 0.7413\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 0.7961 - accuracy: 0.9726 - val_loss: 1.6062 - val_accuracy: 0.7286\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.7965 - accuracy: 0.9687 - val_loss: 1.5443 - val_accuracy: 0.7493\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 0.8354 - accuracy: 0.9666 - val_loss: 1.5839 - val_accuracy: 0.7620\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 9s 47ms/step - loss: 0.8727 - accuracy: 0.9652 - val_loss: 1.6256 - val_accuracy: 0.7500\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 0.8504 - accuracy: 0.9689 - val_loss: 1.6006 - val_accuracy: 0.7540\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 13s 69ms/step - loss: 0.8628 - accuracy: 0.9661 - val_loss: 1.6068 - val_accuracy: 0.7614\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 0.9040 - accuracy: 0.9662 - val_loss: 1.6722 - val_accuracy: 0.7600\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.9385 - accuracy: 0.9642 - val_loss: 1.7954 - val_accuracy: 0.7500\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.9616 - accuracy: 0.9651 - val_loss: 1.8111 - val_accuracy: 0.7400\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.9548 - accuracy: 0.9664 - val_loss: 1.7978 - val_accuracy: 0.7520\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.0024 - accuracy: 0.9629 - val_loss: 1.7525 - val_accuracy: 0.7647\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.9663 - accuracy: 0.9699 - val_loss: 1.6864 - val_accuracy: 0.7594\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 0.9324 - accuracy: 0.9661 - val_loss: 1.8658 - val_accuracy: 0.7366\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 1.0238 - accuracy: 0.9639 - val_loss: 1.7576 - val_accuracy: 0.7493\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 1.0249 - accuracy: 0.9654 - val_loss: 1.6827 - val_accuracy: 0.7654\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 7s 40ms/step - loss: 0.9740 - accuracy: 0.9684 - val_loss: 1.7247 - val_accuracy: 0.7721\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 0.9162 - accuracy: 0.9741 - val_loss: 1.6266 - val_accuracy: 0.7640\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 7s 40ms/step - loss: 0.8458 - accuracy: 0.9724 - val_loss: 1.6748 - val_accuracy: 0.7447\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 0.8485 - accuracy: 0.9691 - val_loss: 1.7225 - val_accuracy: 0.7640\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.9181 - accuracy: 0.9669 - val_loss: 1.7904 - val_accuracy: 0.7580\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 0.9812 - accuracy: 0.9632 - val_loss: 1.8202 - val_accuracy: 0.7460\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 7s 36ms/step - loss: 0.9943 - accuracy: 0.9659 - val_loss: 1.8382 - val_accuracy: 0.7533\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.9809 - accuracy: 0.9676 - val_loss: 1.7467 - val_accuracy: 0.7614\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 7s 36ms/step - loss: 0.9700 - accuracy: 0.9661 - val_loss: 1.7016 - val_accuracy: 0.7694\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 1.0338 - accuracy: 0.9611 - val_loss: 1.7222 - val_accuracy: 0.7553\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.9479 - accuracy: 0.9689 - val_loss: 1.6049 - val_accuracy: 0.7794\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 0.8930 - accuracy: 0.9709 - val_loss: 1.6346 - val_accuracy: 0.7580\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 0.8460 - accuracy: 0.9728 - val_loss: 1.6634 - val_accuracy: 0.7600\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 0.8622 - accuracy: 0.9729 - val_loss: 1.5507 - val_accuracy: 0.7680\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 0.8393 - accuracy: 0.9706 - val_loss: 1.8146 - val_accuracy: 0.7440\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 0.8788 - accuracy: 0.9691 - val_loss: 1.6395 - val_accuracy: 0.7707\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 8s 40ms/step - loss: 0.9551 - accuracy: 0.9667 - val_loss: 1.8327 - val_accuracy: 0.7654\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 1.0170 - accuracy: 0.9636 - val_loss: 1.8759 - val_accuracy: 0.7567\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 1.1498 - accuracy: 0.9580 - val_loss: 2.0371 - val_accuracy: 0.7373\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 1.0027 - accuracy: 0.9711 - val_loss: 1.7316 - val_accuracy: 0.7607\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.8847 - accuracy: 0.9743 - val_loss: 1.6596 - val_accuracy: 0.7580\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.8652 - accuracy: 0.9714 - val_loss: 1.5499 - val_accuracy: 0.7747\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.8312 - accuracy: 0.9708 - val_loss: 1.7815 - val_accuracy: 0.7440\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 0.8217 - accuracy: 0.9711 - val_loss: 1.5583 - val_accuracy: 0.7741\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 9s 47ms/step - loss: 0.8896 - accuracy: 0.9654 - val_loss: 1.6851 - val_accuracy: 0.7654\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.9584 - accuracy: 0.9651 - val_loss: 1.7320 - val_accuracy: 0.7694\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 9s 47ms/step - loss: 0.9509 - accuracy: 0.9687 - val_loss: 1.7078 - val_accuracy: 0.7620\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 0.9265 - accuracy: 0.9686 - val_loss: 1.7398 - val_accuracy: 0.7580\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.9273 - accuracy: 0.9718 - val_loss: 1.6221 - val_accuracy: 0.7874\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 8s 42ms/step - loss: 0.8754 - accuracy: 0.9723 - val_loss: 1.6350 - val_accuracy: 0.7807\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 0.8403 - accuracy: 0.9741 - val_loss: 1.6058 - val_accuracy: 0.7680\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 0.8721 - accuracy: 0.9672 - val_loss: 1.7439 - val_accuracy: 0.7574\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 0.9613 - accuracy: 0.9634 - val_loss: 1.7410 - val_accuracy: 0.7701\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 0.9599 - accuracy: 0.9662 - val_loss: 1.7174 - val_accuracy: 0.7707\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 0.9349 - accuracy: 0.9733 - val_loss: 1.6066 - val_accuracy: 0.7687\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 0.8512 - accuracy: 0.9724 - val_loss: 1.5665 - val_accuracy: 0.7694\n",
            "59/59 [==============================] - 0s 8ms/step - loss: 1.6554 - accuracy: 0.7781\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.7780748605728149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_features_scaled1 = scaler.fit_transform(train_features_dense1)\n",
        "test_features_scaled1 = scaler.transform(test_features_dense1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(152, input_dim=train_features_dense1.shape[1], activation=tf.nn.elu, kernel_regularizer=regularizers.l2(0.1)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(64, input_dim=train_features_dense1.shape[1], activation=tf.nn.elu, kernel_regularizer=regularizers.l2(0.1)),\n",
        "    Dropout(0.5), \n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_features_scaled1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba con datos normalizados\n",
        "loss, accuracy = model.evaluate(test_features_scaled1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba con datos normalizados:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXVO-JXl4LnR",
        "outputId": "e76a312f-721e-4a00-e183-da5ab30a4fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 10s 49ms/step - loss: 7.3077 - accuracy: 0.6895 - val_loss: 3.6353 - val_accuracy: 0.7774\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.3924 - accuracy: 0.8947 - val_loss: 2.6178 - val_accuracy: 0.7513\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 9s 48ms/step - loss: 2.2187 - accuracy: 0.8731 - val_loss: 2.7452 - val_accuracy: 0.7553\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 2.1472 - accuracy: 0.8822 - val_loss: 2.7872 - val_accuracy: 0.7320\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 2.1963 - accuracy: 0.8848 - val_loss: 2.7750 - val_accuracy: 0.7754\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 2.2769 - accuracy: 0.8873 - val_loss: 3.0223 - val_accuracy: 0.7507\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 8s 42ms/step - loss: 2.5823 - accuracy: 0.8904 - val_loss: 3.5596 - val_accuracy: 0.7380\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 2.9995 - accuracy: 0.8828 - val_loss: 4.0596 - val_accuracy: 0.7413\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 3.2188 - accuracy: 0.8884 - val_loss: 3.8677 - val_accuracy: 0.7507\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 9s 45ms/step - loss: 3.1914 - accuracy: 0.8899 - val_loss: 3.6098 - val_accuracy: 0.7360\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.9805 - accuracy: 0.9001 - val_loss: 3.6615 - val_accuracy: 0.7607\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 3.0149 - accuracy: 0.8995 - val_loss: 3.6296 - val_accuracy: 0.7487\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 3.0387 - accuracy: 0.8964 - val_loss: 3.5680 - val_accuracy: 0.7426\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 2.9152 - accuracy: 0.9001 - val_loss: 3.5793 - val_accuracy: 0.7467\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.9473 - accuracy: 0.9039 - val_loss: 3.5997 - val_accuracy: 0.7540\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 3.4140 - accuracy: 0.8949 - val_loss: 4.3798 - val_accuracy: 0.7460\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 3.2701 - accuracy: 0.8980 - val_loss: 4.1192 - val_accuracy: 0.7386\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 3.0383 - accuracy: 0.9087 - val_loss: 3.9006 - val_accuracy: 0.7480\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.9229 - accuracy: 0.9097 - val_loss: 3.3434 - val_accuracy: 0.7487\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 2.9311 - accuracy: 0.9027 - val_loss: 3.8103 - val_accuracy: 0.7533\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 3.5597 - accuracy: 0.8952 - val_loss: 4.7577 - val_accuracy: 0.7380\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 3.5036 - accuracy: 0.9017 - val_loss: 3.8315 - val_accuracy: 0.7553\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 8s 43ms/step - loss: 3.1114 - accuracy: 0.9096 - val_loss: 3.7188 - val_accuracy: 0.7600\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 2.9190 - accuracy: 0.9067 - val_loss: 3.3793 - val_accuracy: 0.7453\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 3.0132 - accuracy: 0.9101 - val_loss: 3.6472 - val_accuracy: 0.7440\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.8204 - accuracy: 0.9107 - val_loss: 3.4727 - val_accuracy: 0.7326\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 9s 48ms/step - loss: 2.9726 - accuracy: 0.9049 - val_loss: 3.8956 - val_accuracy: 0.7320\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 10s 54ms/step - loss: 3.7283 - accuracy: 0.8967 - val_loss: 4.2525 - val_accuracy: 0.7353\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 3.1915 - accuracy: 0.9109 - val_loss: 3.6438 - val_accuracy: 0.7533\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 8s 42ms/step - loss: 2.9293 - accuracy: 0.9079 - val_loss: 4.2489 - val_accuracy: 0.7340\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 3.3016 - accuracy: 0.9074 - val_loss: 3.9364 - val_accuracy: 0.7553\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 3.4118 - accuracy: 0.9074 - val_loss: 3.7947 - val_accuracy: 0.7507\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 3.2380 - accuracy: 0.9094 - val_loss: 3.7873 - val_accuracy: 0.7627\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 9s 47ms/step - loss: 3.0924 - accuracy: 0.9106 - val_loss: 3.8883 - val_accuracy: 0.7433\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.9631 - accuracy: 0.9154 - val_loss: 3.3235 - val_accuracy: 0.7480\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 9s 48ms/step - loss: 2.7297 - accuracy: 0.9144 - val_loss: 3.4712 - val_accuracy: 0.7366\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 3.0811 - accuracy: 0.9131 - val_loss: 4.1358 - val_accuracy: 0.7467\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 9s 48ms/step - loss: 3.0946 - accuracy: 0.9119 - val_loss: 3.7533 - val_accuracy: 0.7447\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.9710 - accuracy: 0.9106 - val_loss: 3.9705 - val_accuracy: 0.7627\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 3.0802 - accuracy: 0.9096 - val_loss: 4.0585 - val_accuracy: 0.7574\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 3.6078 - accuracy: 0.8979 - val_loss: 4.3661 - val_accuracy: 0.7734\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 3.4797 - accuracy: 0.9094 - val_loss: 3.6742 - val_accuracy: 0.7533\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 3.0541 - accuracy: 0.9134 - val_loss: 3.5459 - val_accuracy: 0.7440\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 8s 42ms/step - loss: 2.5945 - accuracy: 0.9186 - val_loss: 3.4257 - val_accuracy: 0.7480\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 2.9730 - accuracy: 0.9039 - val_loss: 3.9671 - val_accuracy: 0.7386\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 8s 40ms/step - loss: 3.5720 - accuracy: 0.8977 - val_loss: 4.2279 - val_accuracy: 0.7467\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 3.4135 - accuracy: 0.9049 - val_loss: 4.0515 - val_accuracy: 0.7286\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 7s 36ms/step - loss: 3.0600 - accuracy: 0.9123 - val_loss: 3.4262 - val_accuracy: 0.7634\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 2.8787 - accuracy: 0.9139 - val_loss: 3.8266 - val_accuracy: 0.7453\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 3.4792 - accuracy: 0.9074 - val_loss: 4.0155 - val_accuracy: 0.7393\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 8s 45ms/step - loss: 3.1635 - accuracy: 0.9143 - val_loss: 3.8745 - val_accuracy: 0.7614\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 3.2760 - accuracy: 0.9102 - val_loss: 3.7447 - val_accuracy: 0.7721\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 9s 46ms/step - loss: 2.9696 - accuracy: 0.9138 - val_loss: 3.7552 - val_accuracy: 0.7380\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 2.9448 - accuracy: 0.9151 - val_loss: 3.2825 - val_accuracy: 0.7607\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 9s 48ms/step - loss: 3.1081 - accuracy: 0.9037 - val_loss: 4.0226 - val_accuracy: 0.7520\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 3.4751 - accuracy: 0.9069 - val_loss: 3.7745 - val_accuracy: 0.7507\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 9s 47ms/step - loss: 3.1023 - accuracy: 0.9069 - val_loss: 3.6462 - val_accuracy: 0.7413\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 7s 40ms/step - loss: 2.9122 - accuracy: 0.9151 - val_loss: 3.4881 - val_accuracy: 0.7400\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 8s 44ms/step - loss: 2.8179 - accuracy: 0.9149 - val_loss: 3.6112 - val_accuracy: 0.7667\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 8s 41ms/step - loss: 3.1850 - accuracy: 0.9082 - val_loss: 3.8379 - val_accuracy: 0.7426\n",
            "59/59 [==============================] - 1s 12ms/step - loss: 3.8933 - accuracy: 0.7572\n",
            "Exactitud en el conjunto de prueba con datos normalizados: 0.7572192549705505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels1)\n",
        "\n",
        "# Convertir las etiquetas en enteros utilizando el LabelEncoder\n",
        "train_labels_encoded1 = le.transform(train_labels1)\n",
        "train_features_dense1 = train_features1.toarray()\n",
        "train_labels_encoded1 = np.array(train_labels_encoded1)\n",
        "\n",
        "test_labels_encoded1 = le.transform(test_labels1)\n",
        "test_features_dense1 = test_features1.toarray()\n",
        "test_labels_encoded1 = np.array(test_labels_encoded1)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(120, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(train_features_dense1, tf.keras.utils.to_categorical(train_labels_encoded1), \n",
        "          epochs = 60, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(test_features_dense1, tf.keras.utils.to_categorical(test_labels_encoded1))\n",
        "\n",
        "print(\"Exactitud en el conjunto de prueba:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPrlp4bq4Lk5",
        "outputId": "39d81643-94c7-4ba6-f843-89effde27295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "187/187 [==============================] - 8s 40ms/step - loss: 1.4309 - accuracy: 0.3769 - val_loss: 1.1392 - val_accuracy: 0.3509\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1236 - accuracy: 0.4250 - val_loss: 1.1244 - val_accuracy: 0.5635\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 1.1408 - accuracy: 0.5268 - val_loss: 1.1285 - val_accuracy: 0.5862\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1586 - accuracy: 0.5768 - val_loss: 1.1396 - val_accuracy: 0.6096\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 6s 35ms/step - loss: 1.1574 - accuracy: 0.5949 - val_loss: 1.1322 - val_accuracy: 0.5989\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.1532 - accuracy: 0.5969 - val_loss: 1.1375 - val_accuracy: 0.6150\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1498 - accuracy: 0.6020 - val_loss: 1.1286 - val_accuracy: 0.6110\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.1300 - accuracy: 0.6111 - val_loss: 1.1299 - val_accuracy: 0.6237\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 6s 31ms/step - loss: 1.1372 - accuracy: 0.6096 - val_loss: 1.1178 - val_accuracy: 0.6190\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 1.1267 - accuracy: 0.6121 - val_loss: 1.1259 - val_accuracy: 0.6063\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 6s 31ms/step - loss: 1.1224 - accuracy: 0.6196 - val_loss: 1.1272 - val_accuracy: 0.6176\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.1222 - accuracy: 0.6273 - val_loss: 1.1080 - val_accuracy: 0.6156\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.1232 - accuracy: 0.6325 - val_loss: 1.1187 - val_accuracy: 0.6136\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.1113 - accuracy: 0.6291 - val_loss: 1.1144 - val_accuracy: 0.6223\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 7s 36ms/step - loss: 1.1139 - accuracy: 0.6336 - val_loss: 1.1180 - val_accuracy: 0.6096\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1172 - accuracy: 0.6293 - val_loss: 1.1087 - val_accuracy: 0.6150\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 1.0995 - accuracy: 0.6316 - val_loss: 1.1089 - val_accuracy: 0.6197\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 6s 31ms/step - loss: 1.1144 - accuracy: 0.6281 - val_loss: 1.1134 - val_accuracy: 0.6197\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 7s 39ms/step - loss: 1.1116 - accuracy: 0.6338 - val_loss: 1.1102 - val_accuracy: 0.6243\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0898 - accuracy: 0.6411 - val_loss: 1.0924 - val_accuracy: 0.6143\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 6s 34ms/step - loss: 1.0951 - accuracy: 0.6343 - val_loss: 1.1162 - val_accuracy: 0.6197\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 7s 35ms/step - loss: 1.1096 - accuracy: 0.6403 - val_loss: 1.1250 - val_accuracy: 0.6230\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 6s 32ms/step - loss: 1.1108 - accuracy: 0.6380 - val_loss: 1.1297 - val_accuracy: 0.6183\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.1075 - accuracy: 0.6435 - val_loss: 1.1113 - val_accuracy: 0.6217\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1102 - accuracy: 0.6385 - val_loss: 1.1156 - val_accuracy: 0.6210\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.0990 - accuracy: 0.6351 - val_loss: 1.1087 - val_accuracy: 0.6197\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1172 - accuracy: 0.6401 - val_loss: 1.1102 - val_accuracy: 0.6170\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 7s 36ms/step - loss: 1.0939 - accuracy: 0.6408 - val_loss: 1.1123 - val_accuracy: 0.6384\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 6s 34ms/step - loss: 1.0985 - accuracy: 0.6440 - val_loss: 1.1099 - val_accuracy: 0.6257\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0965 - accuracy: 0.6493 - val_loss: 1.1081 - val_accuracy: 0.6176\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.1051 - accuracy: 0.6391 - val_loss: 1.1146 - val_accuracy: 0.6210\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0930 - accuracy: 0.6455 - val_loss: 1.1207 - val_accuracy: 0.6163\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.1004 - accuracy: 0.6398 - val_loss: 1.1168 - val_accuracy: 0.6243\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0975 - accuracy: 0.6395 - val_loss: 1.1225 - val_accuracy: 0.6223\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 7s 36ms/step - loss: 1.1028 - accuracy: 0.6428 - val_loss: 1.1158 - val_accuracy: 0.6130\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.0922 - accuracy: 0.6443 - val_loss: 1.1159 - val_accuracy: 0.6237\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 6s 31ms/step - loss: 1.0848 - accuracy: 0.6507 - val_loss: 1.1149 - val_accuracy: 0.6277\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.0939 - accuracy: 0.6462 - val_loss: 1.1225 - val_accuracy: 0.6230\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1020 - accuracy: 0.6438 - val_loss: 1.1120 - val_accuracy: 0.6197\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.0939 - accuracy: 0.6545 - val_loss: 1.1227 - val_accuracy: 0.6250\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0929 - accuracy: 0.6535 - val_loss: 1.1204 - val_accuracy: 0.6190\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.0962 - accuracy: 0.6500 - val_loss: 1.1173 - val_accuracy: 0.6257\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.1002 - accuracy: 0.6485 - val_loss: 1.1284 - val_accuracy: 0.6350\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 6s 32ms/step - loss: 1.0962 - accuracy: 0.6589 - val_loss: 1.1120 - val_accuracy: 0.6297\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.0851 - accuracy: 0.6640 - val_loss: 1.1133 - val_accuracy: 0.6237\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0998 - accuracy: 0.6518 - val_loss: 1.1235 - val_accuracy: 0.6357\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.1005 - accuracy: 0.6570 - val_loss: 1.1272 - val_accuracy: 0.6417\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0970 - accuracy: 0.6679 - val_loss: 1.1244 - val_accuracy: 0.6491\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 7s 35ms/step - loss: 1.0906 - accuracy: 0.6756 - val_loss: 1.1177 - val_accuracy: 0.6390\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.0895 - accuracy: 0.6707 - val_loss: 1.1202 - val_accuracy: 0.6484\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 6s 32ms/step - loss: 1.1050 - accuracy: 0.6694 - val_loss: 1.1256 - val_accuracy: 0.6557\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.1026 - accuracy: 0.6764 - val_loss: 1.1258 - val_accuracy: 0.6571\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 6s 31ms/step - loss: 1.0852 - accuracy: 0.6911 - val_loss: 1.1172 - val_accuracy: 0.6758\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 7s 38ms/step - loss: 1.0857 - accuracy: 0.6913 - val_loss: 1.1146 - val_accuracy: 0.6678\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.1104 - accuracy: 0.6973 - val_loss: 1.1301 - val_accuracy: 0.6925\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.0915 - accuracy: 0.7037 - val_loss: 1.1257 - val_accuracy: 0.6658\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.1118 - accuracy: 0.7093 - val_loss: 1.1269 - val_accuracy: 0.7447\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 6s 33ms/step - loss: 1.1031 - accuracy: 0.7180 - val_loss: 1.1358 - val_accuracy: 0.7045\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 7s 37ms/step - loss: 1.0953 - accuracy: 0.7247 - val_loss: 1.1234 - val_accuracy: 0.7373\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 6s 30ms/step - loss: 1.0956 - accuracy: 0.7359 - val_loss: 1.1361 - val_accuracy: 0.7513\n",
            "59/59 [==============================] - 0s 6ms/step - loss: 1.1080 - accuracy: 0.7711\n",
            "Exactitud en el conjunto de prueba: 0.7711229920387268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk9xLnBL6usv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "\n",
        "# Convertir las etiquetas en enteros utilizando el LabelEncoder\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "\n",
        "train_features_dense = train_features.toarray()\n",
        "train_labels_encoded = np.array(train_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwp3iBipmlpK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(512, input_dim=train_features_dense1.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fH8Qzs9515s"
      },
      "outputs": [],
      "source": [
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuwxEigJ6JpW",
        "outputId": "93189b84-a616-446c-9495-85497dd7534f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "234/234 [==============================] - 52s 216ms/step - loss: 1.7731 - accuracy: 0.5097 - val_loss: 1.2270 - val_accuracy: 0.5957\n",
            "Epoch 2/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 1.2003 - accuracy: 0.6181 - val_loss: 1.2093 - val_accuracy: 0.5979\n",
            "Epoch 3/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 1.1650 - accuracy: 0.6247 - val_loss: 1.1907 - val_accuracy: 0.6198\n",
            "Epoch 4/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 1.1366 - accuracy: 0.6390 - val_loss: 1.1733 - val_accuracy: 0.6241\n",
            "Epoch 5/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 1.1133 - accuracy: 0.6462 - val_loss: 1.1197 - val_accuracy: 0.6465\n",
            "Epoch 6/50\n",
            "234/234 [==============================] - 52s 220ms/step - loss: 1.0690 - accuracy: 0.6565 - val_loss: 1.1037 - val_accuracy: 0.6396\n",
            "Epoch 7/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 1.0478 - accuracy: 0.6683 - val_loss: 1.0847 - val_accuracy: 0.6545\n",
            "Epoch 8/50\n",
            "234/234 [==============================] - 50s 216ms/step - loss: 1.0341 - accuracy: 0.6818 - val_loss: 1.1018 - val_accuracy: 0.6813\n",
            "Epoch 9/50\n",
            "234/234 [==============================] - 49s 211ms/step - loss: 1.0233 - accuracy: 0.7030 - val_loss: 1.0749 - val_accuracy: 0.6947\n",
            "Epoch 10/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 1.0054 - accuracy: 0.7524 - val_loss: 1.0755 - val_accuracy: 0.7824\n",
            "Epoch 11/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 1.0394 - accuracy: 0.8025 - val_loss: 1.1464 - val_accuracy: 0.7722\n",
            "Epoch 12/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 1.0457 - accuracy: 0.8268 - val_loss: 1.1210 - val_accuracy: 0.8027\n",
            "Epoch 13/50\n",
            "234/234 [==============================] - 51s 219ms/step - loss: 1.0388 - accuracy: 0.8338 - val_loss: 1.1136 - val_accuracy: 0.8021\n",
            "Epoch 14/50\n",
            "234/234 [==============================] - 50s 214ms/step - loss: 1.0073 - accuracy: 0.8529 - val_loss: 1.0855 - val_accuracy: 0.8155\n",
            "Epoch 15/50\n",
            "234/234 [==============================] - 49s 209ms/step - loss: 0.9886 - accuracy: 0.8543 - val_loss: 1.0802 - val_accuracy: 0.8139\n",
            "Epoch 16/50\n",
            "234/234 [==============================] - 51s 216ms/step - loss: 0.9636 - accuracy: 0.8607 - val_loss: 1.0879 - val_accuracy: 0.8096\n",
            "Epoch 17/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 0.9401 - accuracy: 0.8699 - val_loss: 1.0679 - val_accuracy: 0.8043\n",
            "Epoch 18/50\n",
            "234/234 [==============================] - 51s 218ms/step - loss: 0.9359 - accuracy: 0.8662 - val_loss: 1.0462 - val_accuracy: 0.8144\n",
            "Epoch 19/50\n",
            "234/234 [==============================] - 49s 209ms/step - loss: 0.9051 - accuracy: 0.8748 - val_loss: 1.0612 - val_accuracy: 0.8155\n",
            "Epoch 20/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 0.9089 - accuracy: 0.8790 - val_loss: 1.0665 - val_accuracy: 0.8155\n",
            "Epoch 21/50\n",
            "234/234 [==============================] - 50s 214ms/step - loss: 0.9074 - accuracy: 0.8751 - val_loss: 1.0848 - val_accuracy: 0.8027\n",
            "Epoch 22/50\n",
            "234/234 [==============================] - 50s 216ms/step - loss: 0.8744 - accuracy: 0.8877 - val_loss: 1.0323 - val_accuracy: 0.8096\n",
            "Epoch 23/50\n",
            "234/234 [==============================] - 51s 216ms/step - loss: 0.8744 - accuracy: 0.8873 - val_loss: 1.0448 - val_accuracy: 0.8187\n",
            "Epoch 24/50\n",
            "234/234 [==============================] - 51s 216ms/step - loss: 0.8732 - accuracy: 0.8885 - val_loss: 1.0637 - val_accuracy: 0.8080\n",
            "Epoch 25/50\n",
            "234/234 [==============================] - 50s 213ms/step - loss: 0.8753 - accuracy: 0.8886 - val_loss: 1.0535 - val_accuracy: 0.8128\n",
            "Epoch 26/50\n",
            "234/234 [==============================] - 49s 209ms/step - loss: 0.8466 - accuracy: 0.8965 - val_loss: 1.0309 - val_accuracy: 0.8134\n",
            "Epoch 27/50\n",
            "234/234 [==============================] - 51s 216ms/step - loss: 0.8477 - accuracy: 0.8933 - val_loss: 1.0426 - val_accuracy: 0.8150\n",
            "Epoch 28/50\n",
            "234/234 [==============================] - 49s 210ms/step - loss: 0.8417 - accuracy: 0.9001 - val_loss: 1.0497 - val_accuracy: 0.8144\n",
            "Epoch 29/50\n",
            "234/234 [==============================] - 51s 218ms/step - loss: 0.8357 - accuracy: 0.9016 - val_loss: 1.0240 - val_accuracy: 0.8198\n",
            "Epoch 30/50\n",
            "234/234 [==============================] - 49s 211ms/step - loss: 0.8267 - accuracy: 0.9052 - val_loss: 1.0338 - val_accuracy: 0.8112\n",
            "Epoch 31/50\n",
            "234/234 [==============================] - 51s 219ms/step - loss: 0.8304 - accuracy: 0.9021 - val_loss: 1.0602 - val_accuracy: 0.8091\n",
            "Epoch 32/50\n",
            "234/234 [==============================] - 50s 214ms/step - loss: 0.8300 - accuracy: 0.9012 - val_loss: 1.0432 - val_accuracy: 0.8182\n",
            "Epoch 33/50\n",
            "234/234 [==============================] - 50s 215ms/step - loss: 0.8275 - accuracy: 0.9036 - val_loss: 1.0528 - val_accuracy: 0.8037\n",
            "Epoch 34/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 0.8272 - accuracy: 0.9012 - val_loss: 1.0676 - val_accuracy: 0.7989\n",
            "Epoch 35/50\n",
            "234/234 [==============================] - 50s 212ms/step - loss: 0.8133 - accuracy: 0.9085 - val_loss: 1.0700 - val_accuracy: 0.8011\n",
            "Epoch 36/50\n",
            "234/234 [==============================] - 51s 218ms/step - loss: 0.8059 - accuracy: 0.9091 - val_loss: 1.0840 - val_accuracy: 0.7925\n",
            "Epoch 37/50\n",
            "234/234 [==============================] - 49s 212ms/step - loss: 0.8134 - accuracy: 0.9060 - val_loss: 1.0619 - val_accuracy: 0.8070\n",
            "Epoch 38/50\n",
            "234/234 [==============================] - 51s 219ms/step - loss: 0.8050 - accuracy: 0.9063 - val_loss: 1.0732 - val_accuracy: 0.7973\n",
            "Epoch 39/50\n",
            "234/234 [==============================] - 50s 212ms/step - loss: 0.7971 - accuracy: 0.9144 - val_loss: 1.0767 - val_accuracy: 0.7979\n",
            "Epoch 40/50\n",
            "234/234 [==============================] - 51s 219ms/step - loss: 0.8012 - accuracy: 0.9088 - val_loss: 1.0601 - val_accuracy: 0.8139\n",
            "Epoch 41/50\n",
            "234/234 [==============================] - 50s 212ms/step - loss: 0.7930 - accuracy: 0.9099 - val_loss: 1.0687 - val_accuracy: 0.8064\n",
            "Epoch 42/50\n",
            "234/234 [==============================] - 51s 219ms/step - loss: 0.7812 - accuracy: 0.9136 - val_loss: 1.0273 - val_accuracy: 0.8166\n",
            "Epoch 43/50\n",
            "234/234 [==============================] - 49s 211ms/step - loss: 0.8050 - accuracy: 0.9085 - val_loss: 1.0575 - val_accuracy: 0.8139\n",
            "Epoch 44/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 0.7944 - accuracy: 0.9159 - val_loss: 1.0396 - val_accuracy: 0.8086\n",
            "Epoch 45/50\n",
            "234/234 [==============================] - 50s 214ms/step - loss: 0.7810 - accuracy: 0.9111 - val_loss: 1.0351 - val_accuracy: 0.8139\n",
            "Epoch 46/50\n",
            "234/234 [==============================] - 51s 217ms/step - loss: 0.7770 - accuracy: 0.9158 - val_loss: 1.0605 - val_accuracy: 0.8123\n",
            "Epoch 47/50\n",
            "234/234 [==============================] - 50s 215ms/step - loss: 0.7843 - accuracy: 0.9179 - val_loss: 1.0363 - val_accuracy: 0.8091\n",
            "Epoch 48/50\n",
            "234/234 [==============================] - 51s 218ms/step - loss: 0.7707 - accuracy: 0.9184 - val_loss: 1.0355 - val_accuracy: 0.8123\n",
            "Epoch 49/50\n",
            "234/234 [==============================] - 50s 215ms/step - loss: 0.7820 - accuracy: 0.9120 - val_loss: 1.0290 - val_accuracy: 0.8134\n",
            "Epoch 50/50\n",
            "234/234 [==============================] - 50s 212ms/step - loss: 0.7797 - accuracy: 0.9120 - val_loss: 1.0370 - val_accuracy: 0.8080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f599427c190>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Entrenar el modelo\n",
        "model.fit(train_features_dense, tf.keras.utils.to_categorical(train_labels_encoded), \n",
        "          epochs=50, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Pz-PguW3AhdP",
        "outputId": "2f3a3a16-ef74-4b3b-8555-28c8fbbcb16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id  \\\n",
              "0     6f4f09622255e9d9d76251b4   \n",
              "1     aefd318f57227e4053f64191   \n",
              "2     d1eb53be99fa263c10911af9   \n",
              "3     bb65250f1ff7582e4380a9c9   \n",
              "4     0017570ee84b80e1c3e10218   \n",
              "...                        ...   \n",
              "1495  4d1dc06d6ca8d0da93ceb42a   \n",
              "1496  db282aa075d8ffb4dc9d72ae   \n",
              "1497  afaac0a39ec1ea5f58308407   \n",
              "1498  262b591834494af862ed6f09   \n",
              "1499  617192c47672548910aca070   \n",
              "\n",
              "                                                   text  \n",
              "0     Le ruego a la Procuradora General @PGN_COL, qu...  \n",
              "1     Más de $51.000 millones de pesos serán inverti...  \n",
              "2     Luchar contra la crisis climática implica camb...  \n",
              "3     1. Hoy en #OpinionesCruzadas de @rcnradio reté...  \n",
              "4     Ante amenazas del ELN y sistemática reducción ...  \n",
              "...                                                 ...  \n",
              "1495  Pido perdón - Periódico Debate Senadora Paola ...  \n",
              "1496  Dos estilos políticos, dos visiones de país:\\n...  \n",
              "1497  #Urgente, nos informan que una compañera del p...  \n",
              "1498  Empresas avícolas del Cauca no pueden sacar lo...  \n",
              "1499                                   #UEVeanLaVerdad   \n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6831d373-1dfa-4033-a3f3-abf9d91b1f4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f4f09622255e9d9d76251b4</td>\n",
              "      <td>Le ruego a la Procuradora General @PGN_COL, qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aefd318f57227e4053f64191</td>\n",
              "      <td>Más de $51.000 millones de pesos serán inverti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d1eb53be99fa263c10911af9</td>\n",
              "      <td>Luchar contra la crisis climática implica camb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bb65250f1ff7582e4380a9c9</td>\n",
              "      <td>1. Hoy en #OpinionesCruzadas de @rcnradio reté...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0017570ee84b80e1c3e10218</td>\n",
              "      <td>Ante amenazas del ELN y sistemática reducción ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>4d1dc06d6ca8d0da93ceb42a</td>\n",
              "      <td>Pido perdón - Periódico Debate Senadora Paola ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>db282aa075d8ffb4dc9d72ae</td>\n",
              "      <td>Dos estilos políticos, dos visiones de país:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>afaac0a39ec1ea5f58308407</td>\n",
              "      <td>#Urgente, nos informan que una compañera del p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>262b591834494af862ed6f09</td>\n",
              "      <td>Empresas avícolas del Cauca no pueden sacar lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>617192c47672548910aca070</td>\n",
              "      <td>#UEVeanLaVerdad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6831d373-1dfa-4033-a3f3-abf9d91b1f4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6831d373-1dfa-4033-a3f3-abf9d91b1f4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6831d373-1dfa-4033-a3f3-abf9d91b1f4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ20RbpbSdWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba907b1-5dc4-4b56-9b89-52ef141b1744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 20ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predecir las categorías de los tweets en el conjunto de prueba\n",
        "test_features_dense = test_features.toarray()\n",
        "\n",
        "Autor = {1: 'Petro', 2: 'Uribe', 0: 'Lopez'}\n",
        "\n",
        "y_pred = model.predict(test_features_dense)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_pred = [Autor[i] for i in y_pred]\n",
        "\n",
        "test['name'] = y_pred\n",
        "test_envio = test.drop(['text'], axis=1)\n",
        "test = test.drop(['name'], axis=1)\n",
        "test_envio.to_csv('modelo_Redes.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E3hOEQFJJfey",
        "outputId": "f81bc9b0-ec3c-4874-bcca-e0a711b80d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id  \\\n",
              "0     6f4f09622255e9d9d76251b4   \n",
              "1     aefd318f57227e4053f64191   \n",
              "2     d1eb53be99fa263c10911af9   \n",
              "3     bb65250f1ff7582e4380a9c9   \n",
              "4     0017570ee84b80e1c3e10218   \n",
              "...                        ...   \n",
              "1495  4d1dc06d6ca8d0da93ceb42a   \n",
              "1496  db282aa075d8ffb4dc9d72ae   \n",
              "1497  afaac0a39ec1ea5f58308407   \n",
              "1498  262b591834494af862ed6f09   \n",
              "1499  617192c47672548910aca070   \n",
              "\n",
              "                                                   text  \n",
              "0     Le ruego a la Procuradora General @PGN_COL, qu...  \n",
              "1     Más de $51.000 millones de pesos serán inverti...  \n",
              "2     Luchar contra la crisis climática implica camb...  \n",
              "3     1. Hoy en #OpinionesCruzadas de @rcnradio reté...  \n",
              "4     Ante amenazas del ELN y sistemática reducción ...  \n",
              "...                                                 ...  \n",
              "1495  Pido perdón - Periódico Debate Senadora Paola ...  \n",
              "1496  Dos estilos políticos, dos visiones de país:\\n...  \n",
              "1497  #Urgente, nos informan que una compañera del p...  \n",
              "1498  Empresas avícolas del Cauca no pueden sacar lo...  \n",
              "1499                                   #UEVeanLaVerdad   \n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18f94c78-70c3-4c11-9865-de07a87c53e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f4f09622255e9d9d76251b4</td>\n",
              "      <td>Le ruego a la Procuradora General @PGN_COL, qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aefd318f57227e4053f64191</td>\n",
              "      <td>Más de $51.000 millones de pesos serán inverti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d1eb53be99fa263c10911af9</td>\n",
              "      <td>Luchar contra la crisis climática implica camb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bb65250f1ff7582e4380a9c9</td>\n",
              "      <td>1. Hoy en #OpinionesCruzadas de @rcnradio reté...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0017570ee84b80e1c3e10218</td>\n",
              "      <td>Ante amenazas del ELN y sistemática reducción ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>4d1dc06d6ca8d0da93ceb42a</td>\n",
              "      <td>Pido perdón - Periódico Debate Senadora Paola ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>db282aa075d8ffb4dc9d72ae</td>\n",
              "      <td>Dos estilos políticos, dos visiones de país:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>afaac0a39ec1ea5f58308407</td>\n",
              "      <td>#Urgente, nos informan que una compañera del p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>262b591834494af862ed6f09</td>\n",
              "      <td>Empresas avícolas del Cauca no pueden sacar lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>617192c47672548910aca070</td>\n",
              "      <td>#UEVeanLaVerdad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18f94c78-70c3-4c11-9865-de07a87c53e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18f94c78-70c3-4c11-9865-de07a87c53e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18f94c78-70c3-4c11-9865-de07a87c53e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_envio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CrOXn5iQA-yt",
        "outputId": "d3aafab9-5a45-4c50-81f1-b7f81783be86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            id   name\n",
              "0     6f4f09622255e9d9d76251b4  Petro\n",
              "1     aefd318f57227e4053f64191  Uribe\n",
              "2     d1eb53be99fa263c10911af9  Petro\n",
              "3     bb65250f1ff7582e4380a9c9  Uribe\n",
              "4     0017570ee84b80e1c3e10218  Lopez\n",
              "...                        ...    ...\n",
              "1495  4d1dc06d6ca8d0da93ceb42a  Uribe\n",
              "1496  db282aa075d8ffb4dc9d72ae  Uribe\n",
              "1497  afaac0a39ec1ea5f58308407  Uribe\n",
              "1498  262b591834494af862ed6f09  Uribe\n",
              "1499  617192c47672548910aca070  Uribe\n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed5a2ea8-759c-4b67-ac2d-3ef6f681f5de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f4f09622255e9d9d76251b4</td>\n",
              "      <td>Petro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aefd318f57227e4053f64191</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d1eb53be99fa263c10911af9</td>\n",
              "      <td>Petro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bb65250f1ff7582e4380a9c9</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0017570ee84b80e1c3e10218</td>\n",
              "      <td>Lopez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>4d1dc06d6ca8d0da93ceb42a</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>db282aa075d8ffb4dc9d72ae</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>afaac0a39ec1ea5f58308407</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>262b591834494af862ed6f09</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>617192c47672548910aca070</td>\n",
              "      <td>Uribe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed5a2ea8-759c-4b67-ac2d-3ef6f681f5de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed5a2ea8-759c-4b67-ac2d-3ef6f681f5de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed5a2ea8-759c-4b67-ac2d-3ef6f681f5de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_csv('modelo_Redes.csv', index=False)"
      ],
      "metadata": {
        "id": "QKlUzm_qA93V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA8xWJ5AMngy"
      },
      "source": [
        "## Xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brZmXioAMnNZ"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7c81pHOOHmH"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V77EPaTOw4r",
        "outputId": "1de783e4-7619-460f-e8e7-4a4211f93758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train_tweets1)\n",
        "train_features1 = vectorizer.transform(train_tweets1)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(test_tweets1)\n",
        "test_features1 = vectorizer.transform(test_tweets1)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels1_encoder = label_encoder.fit_transform(train_labels1)\n",
        "test_labels1_encoder = label_encoder.fit_transform(test_labels1)\n",
        "\n",
        "dtrain = xgb.DMatrix(train_features1, label=train_labels1_encoder)\n",
        "dtest = xgb.DMatrix(test_features1, label=test_labels1_encoder)\n",
        "\n",
        "params = {\n",
        "    'max_depth': 1500,\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': len(train_data['name'].unique()) \n",
        "}\n",
        "\n",
        "model = xgb.train(params, dtrain, num_boost_round=10)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(dtest)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "accuracy = accuracy_score(test_labels1_encoder, y_pred)\n",
        "print(\"Precisión del modelo:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtN1nPqD2oK0",
        "outputId": "0def9bff-1120-4cf0-9589-6c2d45a6dd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.32192513368983955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD-BCppQ2oFl",
        "outputId": "7bf0b10f-27df-4fa9-89b4-fd7cffe6325a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., ..., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ssClRT2oDB",
        "outputId": "9fdf5d51-b587-45cc-dcd9-4fe70754c98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Petro',\n",
              " 'Lopez',\n",
              " 'Petro',\n",
              " 'Uribe',\n",
              " 'Lopez',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhm2NQUGNWtw"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train_tweets)\n",
        "\n",
        "train_features = vectorizer.transform(train_tweets)\n",
        "test_features = vectorizer.transform(test_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npWXkRBAQKY5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['name']= label_encoder.fit_transform(train_data['name'])\n",
        "test_data['name']= label_encoder.fit_transform(test_data['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7baC3MciCKl9"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(train_features, label=train_data['name'])\n",
        "dtest = xgb.DMatrix(test_features, label=test_data['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGf6wqNzQYQS"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'max_depth': 70,\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': len(train_data['name'].unique()) \n",
        "}\n",
        "\n",
        "model = xgb.train(params, dtrain, num_boost_round=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiqfpCAyQkoc",
        "outputId": "109b4f25-5af1-407a-cdaf-61ac4024ac3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión del modelo: 0.7374331550802139\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(dtest)\n",
        "\n",
        "accuracy = accuracy_score(test_data['name'], y_pred)\n",
        "print(\"Precisión del modelo:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUKB81bMwtc9"
      },
      "source": [
        "# Hyperparameter tunning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yX6p-PDxByG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbekmJtw02P"
      },
      "source": [
        "## Logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPoSOPXw0dI",
        "outputId": "f78742d3-2bb5-4f6b-de22-8ccca6950429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros:  {'C': 11.288378916846883, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Score:  0.8423354305971623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "200 fits failed out of a total of 600.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1048, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "100 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.31842863 0.37116271 0.37116271 0.37116271        nan        nan\n",
            " 0.31842863 0.37116271 0.37116271 0.37116271        nan        nan\n",
            " 0.3484821  0.37116271 0.37116271 0.37116271        nan        nan\n",
            " 0.37116271 0.37116271 0.37447822 0.37116271        nan        nan\n",
            " 0.37116271 0.37116271 0.38303591 0.38218018        nan        nan\n",
            " 0.37116271 0.37116271 0.48786036 0.41715733        nan        nan\n",
            " 0.37458517 0.37255308 0.72371339 0.63193912        nan        nan\n",
            " 0.4919286  0.4780193  0.79067138 0.76831672        nan        nan\n",
            " 0.67611431 0.67675539 0.81174273 0.80265068        nan        nan\n",
            " 0.75505355 0.75537332 0.82971299 0.82094185        nan        nan\n",
            " 0.79912253 0.80211775 0.83720117 0.8347407         nan        nan\n",
            " 0.81313396 0.81816133 0.84073069 0.84115862        nan        nan\n",
            " 0.81709147 0.81751859 0.84105189 0.84233543        nan        nan\n",
            " 0.82201206 0.81259835 0.83784322 0.84019616        nan        nan\n",
            " 0.82832336 0.81110142 0.83634573 0.83891263        nan        nan\n",
            " 0.8304628  0.81045994 0.83452731 0.83506207        nan        nan\n",
            " 0.83249494 0.80981857 0.83431312 0.83292264        nan        nan\n",
            " 0.83335062 0.81163652 0.83367141 0.83035539        nan        nan\n",
            " 0.83356458 0.81623597 0.83367141 0.82778826        nan        nan\n",
            " 0.83356446 0.82137063 0.83377837 0.82789533        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'solver': ['saga', 'liblinear']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print(\"Mejores hiperparámetros: \", grid_search.best_params_)\n",
        "print(\"Score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoxPlgEKwv0b"
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegression(C = 11.288378916846883, \n",
        "                         penalty = 'l2', \n",
        "                         solver = 'liblinear')\n",
        "\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "y_pred_logit = clf.predict(test_features)\n",
        "\n",
        "test['name'] = y_pred_logit\n",
        "\n",
        "test.to_csv('modelo_logit_hyp.csv', index=False)\n",
        "test = test.drop(['name'], axis=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XREz8NEeM3yU",
        "6lsWTRLlNFH7",
        "YBnYnLJWNXOL",
        "d8qDM-R1NmfD",
        "9nBNG-vlwPAv",
        "gVgob_tfqj_k",
        "EsNc4l5PsDJh",
        "gWL6QMCctzwb",
        "2-IaI2n1mmx5",
        "QA8xWJ5AMngy"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}